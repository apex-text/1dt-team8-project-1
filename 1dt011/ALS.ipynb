{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75b37366-f017-4fa1-9b20-d311653de494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "        [사용자]\n",
    "           │\n",
    "     ┌─────▼─────┐\n",
    "     │  설문 응답 │  ← 사용자의 취향(장르 등)\n",
    "     └─────┬─────┘\n",
    "           │\n",
    "     ┌─────▼────────────┐\n",
    "     │사용자 성향 벡터 생성│\n",
    "     └─────┬────────────┘\n",
    "           │\n",
    "           ▼\n",
    "[ 사용자 기반 추천 모델 ]  ← Cosine Similarity 등\n",
    "\n",
    "           ▲\n",
    "           │\n",
    "     ┌─────▼─────┐\n",
    "     │ 평점 데이터 │  ← ratings.csv\n",
    "     └─────┬─────┘\n",
    "           ▼\n",
    "   [ ALS 추천 모델 ]  ← Spark ML ALS\n",
    "\n",
    "           ▼\n",
    "  ┌────────┴────────┐\n",
    "  │ Hybrid 추천 조합│ ← 설문 기반 + ALS 기반 결합 (가중 평균 등)\n",
    "  └────────┬────────┘\n",
    "           ▼\n",
    "     [추천 영화 리스트]\n",
    "           ▼\n",
    "       [시각화/출력]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4782788e-6af3-4202-9f0d-7077d5c69cae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col, explode, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1. Unity Catalog에서 데이터 불러오기\n",
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"final\"\n",
    "base_path = f\"{catalog}.{schema}\"\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train = spark.read.table(f\"{base_path}.train_df\")\n",
    "validation = spark.read.table(f\"{base_path}.validation_df\")\n",
    "test = spark.read.table(f\"{base_path}.test_df\")\n",
    "df_movies = spark.read.table(\"`1dt_team8_databricks`.`movielens-small`.movies\") \\\n",
    "                      .withColumn(\"movieId\", col(\"movieId\").cast(\"integer\"))\n",
    "\n",
    "# 2. ALS 모델 정의\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True\n",
    ")\n",
    "\n",
    "# 3. 모델 학습\n",
    "model = als.fit(train)\n",
    "\n",
    "# 4. 특정 사용자 추천 (예: userId 123)\n",
    "user_df = spark.createDataFrame([(123,)], [\"userId\"])\n",
    "userRecs = model.recommendForUserSubset(user_df, 10)\n",
    "\n",
    "# 5. 추천 결과 정리\n",
    "userRecsExploded = userRecs.select(\"userId\", explode(\"recommendations\").alias(\"rec\")) \\\n",
    "                            .select(\"userId\", col(\"rec.movieId\"), col(\"rec.rating\"))\n",
    "\n",
    "# 6. index 부여\n",
    "windowSpec = Window.orderBy(col(\"rating\").desc())\n",
    "indexedRecs = userRecsExploded.withColumn(\"index\", row_number().over(windowSpec) - 1) \\\n",
    "                              .select(\"index\", \"movieId\")\n",
    "\n",
    "# 7. 결과 출력\n",
    "display(indexedRecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55573798-8854-48e4-b9da-cac241d18bd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ML Flow 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63405971-9aef-414d-afae-7d6abe3a2634",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 0. 실험 설정\n",
    "mlflow.set_experiment('/Users/1dt011@msacademy.msai.kr/1dt011')\n",
    "\n",
    "# 1. 데이터 로딩 (Unity Catalog 사용)\n",
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"final\"\n",
    "path = f\"{catalog}.{schema}\"\n",
    "\n",
    "train = spark.read.table(f\"{path}.train_df\")\n",
    "test = spark.read.table(f\"{path}.test_df\")\n",
    "df_movies = spark.read.table(\"`1dt_team8_databricks`.`movielens-small`.movies\") \\\n",
    "                      .withColumn(\"movieId\", col(\"movieId\").cast(\"integer\"))\n",
    "\n",
    "# 2. MLflow 실험 시작\n",
    "with mlflow.start_run(run_name=\"ALS-Recommender-UnityCatalog\"):\n",
    "\n",
    "    # 하이퍼파라미터\n",
    "    rank = 10\n",
    "    maxIter = 10\n",
    "    regParam = 0.1\n",
    "\n",
    "    # ALS 모델 정의 및 학습\n",
    "    als = ALS(\n",
    "        userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "        rank=rank, maxIter=maxIter, regParam=regParam,\n",
    "        coldStartStrategy=\"drop\", nonnegative=True\n",
    "    )\n",
    "\n",
    "    model = als.fit(train)\n",
    "    predictions = model.transform(test)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    # MLflow 로깅\n",
    "    mlflow.log_param(\"rank\", rank)\n",
    "    mlflow.log_param(\"maxIter\", maxIter)\n",
    "    mlflow.log_param(\"regParam\", regParam)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # 모델 저장\n",
    "    mlflow.spark.log_model(model, \"als_model\")\n",
    "\n",
    "    print(f\"✅ MLflow Run Completed - RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4807f8f-4fc0-40ea-a7de-efc09172f0c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 평가지표_ Precision@10 , Recall@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8abecc3-dd42-44eb-afe9-7bad3ea54ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, collect_set, size, array_intersect\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col, explode, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1. Unity Catalog 데이터 불러오기\n",
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"final\"\n",
    "path = f\"{catalog}.{schema}\"\n",
    "\n",
    "train = spark.read.table(f\"{path}.train_df\")\n",
    "test = spark.read.table(f\"{path}.test_df\")\n",
    "\n",
    "# 2. ALS 모델 정의\n",
    "als = ALS(\n",
    "    userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\", nonnegative=True\n",
    ")\n",
    "\n",
    "# 3. 모델 학습\n",
    "model = als.fit(train)\n",
    "\n",
    "# 4. 특정 사용자 추천 (userId 예: 123)\n",
    "user_df = spark.createDataFrame([(123,)], [\"userId\"])\n",
    "userRecs = model.recommendForUserSubset(user_df, 10)\n",
    "\n",
    "# 5. 추천 결과 정리\n",
    "userRecsExploded = userRecs.select(\"userId\", explode(\"recommendations\").alias(\"rec\")) \\\n",
    "                            .select(\"userId\", col(\"rec.movieId\"), col(\"rec.rating\"))\n",
    "\n",
    "# 순위(index) 부여\n",
    "windowSpec = Window.orderBy(col(\"rating\").desc())\n",
    "indexedRecs = userRecsExploded.withColumn(\"index\", row_number().over(windowSpec) - 1) \\\n",
    "                              .select(\"index\", \"movieId\")\n",
    "\n",
    "# 6. 결과 출력\n",
    "\n",
    "# -------------------------------------- #\n",
    "\n",
    "# 7. 테스트셋에서 긍정적 평가(예: rating >= 4.0)만 필터링하여 실제 정답 만들기\n",
    "positive_test = test.filter(col(\"rating\") >= 4.0) \\\n",
    "                    .groupBy(\"userId\") \\\n",
    "                    .agg(collect_set(\"movieId\").alias(\"true_items\"))\n",
    "\n",
    "# 8. 모든 사용자에 대해 추천 10개 생성\n",
    "userRecsAll = model.recommendForAllUsers(10)\n",
    "\n",
    "# 9. 추천 리스트에서 movieId만 추출\n",
    "predicted_items = userRecsAll.select(\"userId\", \n",
    "    expr(\"transform(recommendations, x -> x.movieId)\").alias(\"pred_items\")\n",
    ")\n",
    "\n",
    "# 10. 실제와 예측을 join\n",
    "joined = predicted_items.join(positive_test, on=\"userId\")\n",
    "\n",
    "# 11. Precision@10, Recall@10 계산\n",
    "metrics = joined.withColumn(\"num_relevant_and_recommended\", \n",
    "                                size(array_intersect(\"pred_items\", \"true_items\"))) \\\n",
    "                .withColumn(\"precision_at_10\", \n",
    "                                col(\"num_relevant_and_recommended\") / expr(\"size(pred_items)\")) \\\n",
    "                .withColumn(\"recall_at_10\", \n",
    "                                col(\"num_relevant_and_recommended\") / expr(\"size(true_items)\"))\n",
    "\n",
    "# 12. 평균 값 출력\n",
    "precision_recall = metrics.selectExpr(\"avg(precision_at_10) as avg_precision_at_10\", \n",
    "                                      \"avg(recall_at_10) as avg_recall_at_10\")\n",
    "\n",
    "# 결과 보기\n",
    "precision_recall.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30dbec22-99fe-42e5-9586-113584c06ffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##**개선**\n",
    "✅ 개선 포인트 요약\n",
    "항목\t변경 전\t변경 후 제안\n",
    "\n",
    "ALS 파라미터\t기본값 사용\trank, maxIter, regParam 조정\n",
    "\n",
    "추천 수\tTop 10\tTop 50으로 늘리고 그중 상위 N개 평가\n",
    "\n",
    "추천 유저\t고정 userId\t다수 유저에 대해 평가 자동화 가능하게\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7baaf6d-e85f-43ac-b55e-8d84e5910f04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col, explode, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1. Unity Catalog에서 데이터 불러오기\n",
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"final\"\n",
    "base_path = f\"{catalog}.{schema}\"\n",
    "\n",
    "train = spark.read.table(f\"{base_path}.train_df\")\n",
    "validation = spark.read.table(f\"{base_path}.validation_df\")\n",
    "test = spark.read.table(f\"{base_path}.test_df\")\n",
    "\n",
    "df_movies = spark.read.table(\"`1dt_team8_databricks`.`movielens-small`.movies\") \\\n",
    "                      .withColumn(\"movieId\", col(\"movieId\").cast(\"integer\"))\n",
    "\n",
    "# 2. ALS 모델 정의 (파라미터 조정)\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    "    rank=20,\n",
    "    maxIter=15,\n",
    "    regParam=0.1\n",
    ")\n",
    "\n",
    "# 3. 모델 학습\n",
    "model = als.fit(train)\n",
    "\n",
    "# 4. 추천 대상 사용자 설정\n",
    "user_ids = [123]  # 하나의 사용자만 추천할 경우\n",
    "user_df = spark.createDataFrame([(uid,) for uid in user_ids], [\"userId\"])\n",
    "\n",
    "# 5. Top 50 추천 받아서 Top 10만 출력\n",
    "userRecs = model.recommendForUserSubset(user_df, 50)\n",
    "\n",
    "# 6. 추천 결과 정리\n",
    "userRecsExploded = userRecs.select(\"userId\", explode(\"recommendations\").alias(\"rec\")) \\\n",
    "                            .select(\"userId\", col(\"rec.movieId\"), col(\"rec.rating\"))\n",
    "\n",
    "# 7. Top 10 영화만 index 부여하여 추출\n",
    "windowSpec = Window.partitionBy(\"userId\").orderBy(col(\"rating\").desc())\n",
    "topN = 10\n",
    "\n",
    "indexedRecs = userRecsExploded.withColumn(\"index\", row_number().over(windowSpec) - 1) \\\n",
    "                              .filter(col(\"index\") < topN) \\\n",
    "                              .select(\"index\", \"movieId\")\n",
    "\n",
    "# 8. 결과 출력\n",
    "display(indexedRecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e699478-0203-404f-95b8-0c655f9c0f16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct, collect_set, size\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. 추천 결과(topNRecs)에는 userId, movieId가 포함되어 있어야 함\n",
    "#    topNRecs: ALS로 추천된 Top 10 movie per user\n",
    "\n",
    "# 2. 실제 평가 데이터에서 평점 4.0 이상인 영화만 긍정적으로 간주\n",
    "actual_relevant = test.filter(col(\"rating\") >= 4.0) \\\n",
    "                      .select(\"userId\", \"movieId\") \\\n",
    "                      .distinct() \\\n",
    "                      .groupBy(\"userId\") \\\n",
    "                      .agg(collect_set(\"movieId\").alias(\"actual_movies\"))\n",
    "\n",
    "# 3. 추천 결과를 userId별로 movieId 리스트로 집계\n",
    "predicted_recs = topNRecs.groupBy(\"userId\") \\\n",
    "                         .agg(collect_set(\"movieId\").alias(\"predicted_movies\"))\n",
    "\n",
    "# 4. 실제/예측 join\n",
    "joined = predicted_recs.join(actual_relevant, on=\"userId\", how=\"inner\")\n",
    "\n",
    "# 5. Precision@10, Recall@10 계산\n",
    "def precision_recall_udf(predicted, actual):\n",
    "    predicted_set = set(predicted)\n",
    "    actual_set = set(actual)\n",
    "    intersection = predicted_set & actual_set\n",
    "    precision = len(intersection) / len(predicted_set) if predicted_set else 0.0\n",
    "    recall = len(intersection) / len(actual_set) if actual_set else 0.0\n",
    "    return (precision, recall)\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"precision\", DoubleType(), True),\n",
    "    StructField(\"recall\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "precision_recall_udf_spark = udf(precision_recall_udf, schema)\n",
    "\n",
    "# 6. 컬럼 생성\n",
    "scored = joined.withColumn(\"metrics\", precision_recall_udf_spark(col(\"predicted_movies\"), col(\"actual_movies\"))) \\\n",
    "               .select(\"userId\", \"metrics.*\")\n",
    "\n",
    "# 7. 평균 계산\n",
    "avg_scores = scored.select(F.avg(\"precision\").alias(\"avg_precision_at_10\"),\n",
    "                           F.avg(\"recall\").alias(\"avg_recall_at_10\"))\n",
    "\n",
    "# 8. 출력\n",
    "display(avg_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bcf8507-b5a8-4250-9ec0-b8a5ec26a960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 지표 이름\n",
    "metrics = ['Precision@10', 'Recall@10']\n",
    "\n",
    "# 개선 전, 후 값\n",
    "before = [0.00387, 0.00422]\n",
    "after = [0.01356, 0.01423]\n",
    "\n",
    "x = np.arange(len(metrics))  # X축 위치\n",
    "width = 0.35                 # 바 너비\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "bars1 = ax.bar(x - width/2, before, width, label='Before', color='lightcoral')\n",
    "bars2 = ax.bar(x + width/2, after, width, label='After', color='skyblue')\n",
    "\n",
    "# 레이블 및 타이틀\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Avg Precision@10 and Recall@10 (Before vs After)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "# 값 표시 (소수점 3자리)\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 텍스트 오프셋\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(bars1)\n",
    "autolabel(bars2)\n",
    "\n",
    "plt.ylim(0, max(after) + 0.005)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ALS",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
