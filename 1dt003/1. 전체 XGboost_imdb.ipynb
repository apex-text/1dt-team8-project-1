{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df6560ad-7649-41be-9586-1f87284eb0f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#0. 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a63e34d-3598-4d68-9e26-58c35dde5537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count, regexp_extract, regexp_replace, row_number\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, VectorAssembler, MinMaxScaler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa284b47-d962-47a9-b990-5bbfaeaff070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"XGBoost\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c84e855-ddbe-45c0-82c9-b005c7c0f5f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. 데이터로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb46cb5-c0a1-4072-963f-a6f9974d1175",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c20c36-c995-422e-9661-24d5b2075724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"`final`\"\n",
    "path = f\"{catalog}.{schema}\"\n",
    "\n",
    "try:\n",
    "    train = spark.read.table(f\"{path}.train_df\")\n",
    "    validation = spark.read.table(f\"{path}.validation_df\")\n",
    "    test = spark.read.table(f\"{path}.test_df\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data from Unity Catalog Volume: {e}\")\n",
    "# display(train)\n",
    "# display(validation)\n",
    "# display(test)\n",
    "\n",
    "train = train.withColumn(\"label\", when(train[\"rating\"] >= 4, 1).otherwise(0))\n",
    "validation = validation.withColumn(\"label\", when(validation[\"rating\"] >= 4, 1).otherwise(0))\n",
    "test = test.withColumn(\"label\", when(test[\"rating\"] >= 4, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96a9659d-6f72-4d65-b112-ba1ab26c033f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### IMDB 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b4db14-6319-4e29-ae78-ebed6d258de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"`imdb`\"\n",
    "imdb_path = f\"{catalog}.{schema}\"\n",
    "\n",
    "try:\n",
    "    imdb_ratings = spark.read.table(f\"{imdb_path}.title_ratings\")\n",
    "    print(\"Data loaded successfully from Unity Catalog Volume.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data from Unity Catalog Volume: {e}\")\n",
    "    print(f\"Please ensure CSV files (imdb_ratings.csv) exist in {imdb_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dd78242-4c3f-499c-b9de-b0d0ffe62988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. 데이터분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66a39b18-7335-4eff-a3fa-0e6f4864f6c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3ce0016-1734-4b33-ace4-6010f3075ad3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"genres\", outputCol=\"genres_tokens\", pattern=\"\\\\|\")\n",
    "vectorizer = CountVectorizer(inputCol=\"genres_tokens\", outputCol=\"genres_vec\")\n",
    "# assembler_numvotes = VectorAssembler(inputCols=[\"numVotes\"], outputCol=\"numVotes_vec\")\n",
    "# scaler = MinMaxScaler(inputCol=\"numVotes_vec\", outputCol=\"numVotes_scaled\")\n",
    "user_indexer = StringIndexer(inputCol=\"userId\", outputCol=\"userIndex\")\n",
    "user_indexer_model = user_indexer.fit(train)\n",
    "movie_indexer = StringIndexer(inputCol=\"movieId\", outputCol=\"movieIndex\")\n",
    "\n",
    "assembler_all = VectorAssembler(\n",
    "    # inputCols=[\"genres_vec\", \"averageRating\", \"numVotes_scaled\", \"userIndex\", \"movieIndex\", \"year\"],\n",
    "    inputCols=[\"genres_vec\", \"userIndex\", \"movieIndex\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    # tokenizer, vectorizer, assembler_numvotes, scaler,\n",
    "    # user_indexer, movie_indexer, assembler_all\n",
    "    tokenizer, vectorizer, \n",
    "    user_indexer, movie_indexer, assembler_all\n",
    "])\n",
    "\n",
    "pipeline_model = pipeline.fit(train)\n",
    "train_transformed = pipeline_model.transform(train)\n",
    "validation_transformed = pipeline_model.transform(validation)\n",
    "test_transformed = pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4db8ca36-054a-48ba-90ac-87c186624928",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_count = train_transformed.count()\n",
    "chunk_size = total_count // 3\n",
    "window_spec = Window.orderBy(\"userId\")  # 유일한 컬럼 기준 정렬\n",
    "\n",
    "df_with_rownum = train_transformed.withColumn(\"row_num\", row_number().over(window_spec))\n",
    "\n",
    "dfs = []\n",
    "for i in range(3):\n",
    "    start = i * chunk_size + 1\n",
    "    end = (i + 1) * chunk_size if i < 2 else total_count\n",
    "\n",
    "    chunk_df = df_with_rownum.filter((col(\"row_num\") >= start) & (col(\"row_num\") <= end)).drop(\"row_num\")\n",
    "    chunk_df = chunk_df.withColumn(\"features_array\", vector_to_array(\"features\"))\n",
    "\n",
    "    # ✅ 필요한 컬럼들 선택\n",
    "    chunk_pd = chunk_df.select(\"userIndex\", \"movieIndex\", \"features_array\", \"label\").toPandas()\n",
    "    dfs.append(chunk_pd)\n",
    "\n",
    "train_pd = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5541b210-cb76-4b2c-ae2c-a13ba03c1856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "val_total_count = validation_transformed.count()\n",
    "val_chunk_size = val_total_count // 3\n",
    "val_window_spec = Window.orderBy(\"userId\")  # 유일한 컬럼 기준 정렬\n",
    "\n",
    "val_with_rownum = validation_transformed.withColumn(\"row_num\", row_number().over(val_window_spec))\n",
    "\n",
    "val_dfs = []\n",
    "for i in range(3):\n",
    "    start = i * val_chunk_size + 1\n",
    "    end = (i + 1) * val_chunk_size if i < 2 else val_total_count\n",
    "\n",
    "    chunk_df = val_with_rownum.filter((col(\"row_num\") >= start) & (col(\"row_num\") <= end)).drop(\"row_num\")\n",
    "    chunk_df = chunk_df.withColumn(\"features_array\", vector_to_array(\"features\"))\n",
    "\n",
    "    # ✅ 필요한 컬럼들 선택\n",
    "    chunk_pd = chunk_df.select(\"userIndex\", \"movieIndex\", \"features_array\", \"label\").toPandas()\n",
    "    val_dfs.append(chunk_pd)\n",
    "\n",
    "validation_pd = pd.concat(val_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb42163c-995b-44ac-8e35-5ffae97bfd4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. 총 개수와 청크 크기 정의\n",
    "test_total_count = test_transformed.count()\n",
    "test_chunk_size = test_total_count // 3\n",
    "test_window_spec = Window.orderBy(\"userId\")  # 고유 컬럼 기준 정렬\n",
    "\n",
    "# 2. row_num 생성\n",
    "test_with_rownum = test_transformed.withColumn(\"row_num\", row_number().over(test_window_spec))\n",
    "\n",
    "# 3. 3개로 나눠서 Pandas 변환 (필수 컬럼 포함)\n",
    "test_dfs = []\n",
    "for i in range(3):\n",
    "    start = i * test_chunk_size + 1\n",
    "    end = (i + 1) * test_chunk_size if i < 2 else test_total_count\n",
    "\n",
    "    chunk_df = test_with_rownum.filter((col(\"row_num\") >= start) & (col(\"row_num\") <= end)).drop(\"row_num\")\n",
    "    chunk_df = chunk_df.withColumn(\"features_array\", vector_to_array(\"features\"))\n",
    "    \n",
    "    # 필요한 컬럼 전부 선택\n",
    "    chunk_pd = chunk_df.select(\"userIndex\", \"movieIndex\", \"features_array\", \"label\").toPandas()\n",
    "    test_dfs.append(chunk_pd)\n",
    "\n",
    "# 4. 합치기\n",
    "test_pd = pd.concat(test_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a138d04-2b5c-42bf-8df1-e3f3506bd646",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# X (features), y (labels) 분리\n",
    "X_train = np.array(train_pd['features_array'].tolist())\n",
    "y_train = train_pd['label'].astype(int).values\n",
    "\n",
    "X_valid = np.array(validation_pd['features_array'].tolist())\n",
    "y_valid = validation_pd['label'].astype(int).values\n",
    "\n",
    "X_test = np.array(test_pd['features_array'].tolist())\n",
    "y_test = test_pd['label'].astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c41418dd-1adf-4548-a228-9ef00c6a3a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. 모델 설계 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3351bff2-1c8f-414d-8f7c-2235638d1670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 평가지표 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85914ef9-eaa4-4aec-9474-a5de7fea1b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Precision@K 계산 함수\n",
    "def precision_at_k(df: pd.DataFrame, k: int = 5, threshold: float = 4.0) -> float:\n",
    "    top_k = (\n",
    "        df.sort_values([\"userIndex\", \"y_pred_proba\"], ascending=[True, False])\n",
    "        .groupby(\"userIndex\")\n",
    "        .head(k)\n",
    "    )\n",
    "    top_k[\"hit\"] = (top_k[\"y_true\"] >= threshold).astype(int)\n",
    "    user_precision = top_k.groupby(\"userIndex\")[\"hit\"].mean()\n",
    "    return user_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee7b37b3-b8bf-46ab-823d-288e6388afab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def recall_at_k(df: pd.DataFrame, k: int = 5, threshold: float = 4.0) -> float:\n",
    "    # 사용자별 실제 긍정(평점 >= threshold) 아이템 수\n",
    "    user_positive_counts = df[df[\"y_true\"] >= threshold].groupby(\"userIndex\").size()\n",
    "\n",
    "    # 사용자별 top-k 추천 추출\n",
    "    top_k = (\n",
    "        df.sort_values([\"userIndex\", \"y_pred_proba\"], ascending=[True, False])\n",
    "        .groupby(\"userIndex\")\n",
    "        .head(k)\n",
    "        .copy()\n",
    "    )\n",
    "    top_k[\"hit\"] = (top_k[\"y_true\"] >= threshold).astype(int)\n",
    "\n",
    "    # 사용자별 top-k 추천에서 맞춘 아이템 수\n",
    "    user_hits = top_k.groupby(\"userIndex\")[\"hit\"].sum()\n",
    "\n",
    "    # 사용자별 recall 계산 (실제 긍정 아이템 수가 0인 경우 제외)\n",
    "    recall_per_user = user_hits / user_positive_counts\n",
    "    recall_per_user = recall_per_user.dropna()  # NaN 처리 (실제 긍정 아이템이 없는 사용자 제외)\n",
    "\n",
    "    # 전체 사용자 평균 Recall@K 반환\n",
    "    return recall_per_user.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adac5c51-4f58-466c-a8f5-c38462e79611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ndcg_at_k(df: pd.DataFrame, k: int = 10) -> float:\n",
    "    def dcg(relevances):\n",
    "        return np.sum((2**relevances - 1) / np.log2(np.arange(2, relevances.size + 2)))\n",
    "\n",
    "    ndcgs = []\n",
    "\n",
    "    for user, group in df.groupby(\"userIndex\"):\n",
    "        # user별 y_pred_proba 기준 내림차순 정렬, top-k 추출\n",
    "        top_k = group.sort_values(\"y_pred_proba\", ascending=False).head(k)\n",
    "        rel = top_k[\"y_true\"].values\n",
    "        \n",
    "        # 이상적인 순서(내림차순 y_true 정렬)\n",
    "        ideal_rel = np.sort(group[\"y_true\"].values)[::-1][:k]\n",
    "        \n",
    "        actual_dcg = dcg(rel)\n",
    "        ideal_dcg = dcg(ideal_rel)\n",
    "\n",
    "        ndcg = actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3f9a08-fbea-4caf-a2f8-a2bcbc8eb528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## XgbClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3d5f30b-860d-4e0b-b96e-503c79ac1921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 모델 설계 및 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c695f2b-6659-413d-bff7-ab632b6a7e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    max_depth=6,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    early_stopping_rounds=50,\n",
    "    seed=0,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8582d4b-e9d5-4128-ac3e-5ba14e76b75c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_pdf = test_pd.copy()\n",
    "test_pdf[\"y_pred\"] = y_pred\n",
    "test_pdf[\"y_pred_proba\"] = y_pred_proba\n",
    "test_pdf[\"y_true\"] = test_pdf[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5ab45d3-cc01-48a8-8d06-762cb7f40830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfe269c4-169c-4367-a003-9a2700009135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "p_at_10 = precision_at_k(test_pdf, k=10)\n",
    "print(f\"Precision@10: {p_at_10:.4f}\")\n",
    "\n",
    "r_at_10 = recall_at_k(test_pdf, k=10)\n",
    "print(f\"Recall@10: {r_at_10:.4f}\")\n",
    "\n",
    "ndcg_10 = ndcg_at_k(test_pdf, k=10)\n",
    "print(f\"NDCG@10: {ndcg_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ddc6716-89a5-47e0-8133-ed3e70fca7ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 사용자별 추천 영화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f2c48e1-7c54-44ee-a2c1-c93e0a7074f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "K = 10\n",
    "\n",
    "# 1. 사용자별 예측 상위 K개 영화 선택\n",
    "window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_proba\").desc())\n",
    "\n",
    "ranked = test_pred.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "                  .filter(col(\"rank\") <= K)\n",
    "\n",
    "# 2. 추천 영화 정보 묶기 (movieIndex와 예측 확률)\n",
    "ranked = ranked.withColumn(\"recommendation\", struct(col(\"movieIndex\").alias(\"movieId\"), col(\"y_pred_proba\").alias(\"pred_rating\")))\n",
    "\n",
    "# 3. 사용자별로 리스트로 그룹화\n",
    "recommendations = ranked.groupBy(\"userIndex\") \\\n",
    "    .agg(collect_list(\"recommendation\").alias(\"recommendations\")) \\\n",
    "    .orderBy(\"userIndex\")\n",
    "\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe6508e-3f62-40ce-8b5f-1db17423b958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94853fc0-5461-456d-b16e-53a4440cd062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 레이블 생성 (평점 4 이상은 1, 아니면 0)\n",
    "# Optuna 목적 함수 정의\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 설정\n",
    "    param = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"early_stopping_rounds\" : 20\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델 학습\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],  verbose=False)\n",
    "\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    test_pdf = test_df.select(\"userIndex\", \"movieIndex\", \"rating\").toPandas()\n",
    "    test_pdf[\"y_pred_prob\"] = y_pred\n",
    "    test_pdf.rename(columns={\"rating\": \"y_true\"}, inplace=True)\n",
    "\n",
    "    pred = spark.createDataFrame(test_pdf)\n",
    "\n",
    "    window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_prob\").desc())\n",
    "    top_k = pred.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= K)\n",
    "\n",
    "    # Precision@K 계산\n",
    "    top_k = top_k.withColumn(\"y_true\", (col(\"y_true\") >= 4).cast(\"int\"))\n",
    "    precision_df = top_k.groupBy(\"userIndex\").agg({\"y_true\": \"avg\"})\n",
    "    avg_precision_at_k = precision_df.selectExpr(\"avg(`avg(y_true)`) as precision_at_k\").collect()[0][\"precision_at_k\"]\n",
    "\n",
    "    return avg_precision_at_k  # Optuna는 최소화를 수행하므로 음수 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f951dd2-06c5-4341-9304-511f576ee2a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # Precision@K를 최대화\n",
    "study.optimize(objective, n_trials=30)  # 30번 튜닝\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best Precision@K:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e4d62ef-5080-4e5a-940a-79854f8f77e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "best_pred = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 1. 디렉토리 생성\n",
    "os.makedirs(\"/dbfs/FileStore/models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, \"/dbfs/FileStore/models/best_xgb_clf_model.pkl\")\n",
    "\n",
    "# loaded_model = joblib.load(\"best_xgb_model.pkl\")\n",
    "# y_pred = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23be3ade-a42e-45a8-81de-d9e05d1c4e33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Optuna + mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "249b1791-ea01-408a-9788-851f209ea82f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 레이블 생성 (평점 4 이상은 1, 아니면 0)\n",
    "# Optuna 목적 함수 정의\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 설정\n",
    "    param = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"early_stopping_rounds\": 20\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "            # ✅ 파라미터 기록\n",
    "            mlflow.log_params(param)\n",
    "\n",
    "            # XGBoost 모델 학습\n",
    "            model = XGBRegressor(**param)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "\n",
    "            # 예측\n",
    "            y_pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            # Spark DataFrame으로 Precision@K 계산\n",
    "            test_pdf = test_df.select(\"userIndex\", \"movieIndex\", \"rating\").toPandas()\n",
    "            test_pdf[\"y_pred_prob\"] = y_pred\n",
    "            test_pdf.rename(columns={\"rating\": \"y_true\"}, inplace=True)\n",
    "\n",
    "            pred = spark.createDataFrame(test_pdf)\n",
    "            window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_prob\").desc())\n",
    "            top_k = pred.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= K)\n",
    "\n",
    "            top_k = top_k.withColumn(\"y_true\", (col(\"y_true\") >= 4).cast(\"int\"))\n",
    "            precision_df = top_k.groupBy(\"userIndex\").agg({\"y_true\": \"avg\"})\n",
    "            avg_precision_at_k = precision_df.selectExpr(\"avg(`avg(y_true)`) as precision_at_k\").collect()[0][\"precision_at_k\"]\n",
    "\n",
    "            # ✅ 메트릭 기록\n",
    "            mlflow.log_metric(\"precision_at_k\", avg_precision_at_k)\n",
    "\n",
    "            # ✅ 모델 저장\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "            return -avg_precision_at_k  # Optuna는 최소화 수행하므로 음수로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f5baedf-abff-49b9-9002-f255e082551e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(**study.best_params)\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "\n",
    "with mlflow.start_run(run_name=\"final_best_model\"):\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.sklearn.log_model(best_model, \"final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "336a1e5e-b149-4b35-b47b-81765882f8c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 5. 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15903bf-26d8-4ccb-bc6e-02739385b5a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5-1. 안 본 영화 중에서 추천(rating 있다면 본 영화로 판단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03fed727-1895-43aa-85a1-83e5a09c2920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "# 1. 사용자별 이미 본 영화(movieIndex) 집합 생성 (train + valid + test 혹은 전체 학습 데이터에서)\n",
    "# 보통은 train_df, valid_df에 있는 user-movie pairs가 '본 영화'임\n",
    "seen_movies_df = train_df.select(\"userIndex\", \"movieIndex\") \\\n",
    "    .union(valid_df.select(\"userIndex\", \"movieIndex\")) \\\n",
    "    .distinct() \\\n",
    "    .groupBy(\"userIndex\") \\\n",
    "    .agg(collect_set(\"movieIndex\").alias(\"seen_movies\"))\n",
    "\n",
    "# 2. test_pred와 join해서 이미 본 영화 제외\n",
    "test_pred_filtered = test_pred.join(seen_movies_df, on=\"userIndex\", how=\"left_outer\")\n",
    "\n",
    "# 3. 이미 본 영화 제외 조건 추가 (seen_movies가 null일 수도 있으니 null-safe 처리)\n",
    "from pyspark.sql.functions import array_contains\n",
    "\n",
    "test_pred_filtered = test_pred_filtered.filter(\n",
    "    (col(\"seen_movies\").isNull()) | (~array_contains(col(\"seen_movies\"), col(\"movieIndex\")))\n",
    ")\n",
    "\n",
    "# 4. 사용자별 추천 상위 K개 추출\n",
    "window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_prob\").desc())\n",
    "\n",
    "ranked = test_pred_filtered.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "                           .filter(col(\"rank\") <= K)\n",
    "\n",
    "ranked = ranked.withColumn(\"recommendation\", struct(col(\"movieIndex\").alias(\"movieId\"), col(\"y_pred_prob\").alias(\"pred_rating\")))\n",
    "\n",
    "recommendations = ranked.groupBy(\"userIndex\") \\\n",
    "                        .agg(collect_list(\"recommendation\").alias(\"recommendations\")) \\\n",
    "                        .orderBy(\"userIndex\")\n",
    "\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c358f4c5-fd3b-4f32-ba22-5d9de4da1e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5-2. 추가 User가 들어왔을때 어떤 영화를 추천할지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3718f019-6ea2-41ec-8933-43a29bdeadd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. 신규유저에 영화정보를 바탕으로 기존유저와 매칭\n",
    "\n",
    "2. 새로운 user_index 추천하지 않음(새로 학습해야함) - 현재 모델에서 user_index가 중요한 역할/ 처음 보는 User_index보고 엉뚱한 예측할 확률 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fee224e-92a9-4de2-ac4f-75235d197416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Cold Start 유저 처리\n",
    "신규 유저:\n",
    "\n",
    "A안: userIndex 제거한 일반 모델로 추천 제공 (장르, 평균 평점 기반)\n",
    "\n",
    "B안: 기존 유저와 유사도 기반으로 매칭 → 그 유저의 추천을 가져옴 (collaborative filtering 유사)\n",
    "\n",
    "2. 데이터 업데이트 및 재학습\n",
    "신규 rating이 수집되면 데이터에 추가\n",
    "\n",
    "일정 주기 (일간/주간 등)에 따라 모델 재학습\n",
    "\n",
    "재학습된 모델은 최신화된 추천 반영 가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2ebbe93-2b8f-4de8-890e-c215532cc734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. 시청 영화 바탕으로 유사한 기존 유저 indexr를 찾고,\n",
    "2. 그 indexr와 시청 영화 바탕으로 추천 영화 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c576c02a-1857-4abe-9e70-7b940939a29e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1. 신규 유저가 본 영화 리스트\n",
    "new_user_seen_movies = [1, 10, 50, 300]\n",
    "new_user_set = set(new_user_seen_movies)\n",
    "\n",
    "# Step 2. 기존 유저별 시청 영화 집합 생성\n",
    "user_movie_sets = ratings.groupBy(\"userId\").agg(collect_set(\"movieId\").alias(\"movie_set\"))\n",
    "\n",
    "# Step 3. Jaccard 유사도 계산\n",
    "def jaccard_similarity(set1, set2):\n",
    "    set1, set2 = set(set1), set(set2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return float(intersection) / union if union != 0 else 0.0\n",
    "\n",
    "jaccard_udf = udf(lambda x: jaccard_similarity(new_user_set, x), DoubleType())\n",
    "\n",
    "similar_users = user_movie_sets.withColumn(\"jaccard_sim\", jaccard_udf(col(\"movie_set\"))) \\\n",
    "                               .orderBy(desc(\"jaccard_sim\")) \\\n",
    "                               .limit(1)\n",
    "\n",
    "# Step 4. 유사한 기존 유저의 userId 및 userIndex 추출\n",
    "top_user_id = similar_users.select(\"userId\").first()[\"userId\"]\n",
    "top_user_index = user_indexer_model.transform(\n",
    "    spark.createDataFrame([(top_user_id,)], [\"userId\"])\n",
    ").select(\"userIndex\").first()[\"userIndex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74601779-6f8e-4c38-a3be-74da9af315aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 5. 전체 영화 목록에서, 신규 유저가 보지 않은 영화만 필터링\n",
    "unseen_movies = df_cleaned.filter(~col(\"movieId\").isin(new_user_seen_movies))\n",
    "\n",
    "# Step 6. 추천 후보 영화들에 대해 movieIndex, features 등 변환 수행\n",
    "unseen_with_features = pipeline_model.transform(unseen_movies)\n",
    "\n",
    "# Step 7. 해당 유사 유저 index를 모든 row에 추가\n",
    "unseen_with_features = unseen_with_features.withColumn(\"userIndex\", lit(top_user_index))\n",
    "\n",
    "unseen_unique = unseen_with_features.dropDuplicates([\"movieId\"])\n",
    "\n",
    "# Step 8. features 컬럼을 numpy 배열로 변환\n",
    "pdf_unseen = unseen_unique.select(\"features\", \"movieId\", \"title\").toPandas()\n",
    "X_unseen = np.vstack(pdf_unseen[\"features\"].apply(lambda x: x.toArray()))\n",
    "\n",
    "# Step 9. 모델 예측 (regressor라 predict_proba 아님, predict 사용)\n",
    "y_pred = model.predict_proba(X_unseen)[:,1]\n",
    "\n",
    "# Step 10. 예측 결과를 DataFrame에 추가\n",
    "pdf_unseen[\"prediction\"] = y_pred\n",
    "\n",
    "# Step 11. 상위 K개 추천\n",
    "top_k = pdf_unseen.sort_values(by=\"prediction\", ascending=False).head(10)\n",
    "\n",
    "# 출력\n",
    "print(top_k[[\"movieId\", \"title\", \"prediction\"]])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7760516635777470,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1. 전체 XGboost_imdb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
