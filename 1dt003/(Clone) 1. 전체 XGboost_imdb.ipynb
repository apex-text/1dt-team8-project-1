{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df6560ad-7649-41be-9586-1f87284eb0f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#0. 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "66831ff2-6fdb-4f55-a673-c09fdbc52d9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a63e34d-3598-4d68-9e26-58c35dde5537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count, regexp_extract, regexp_replace, row_number, desc, udf, lit\n",
    "from pyspark.sql.functions import struct, array_contains, collect_set, collect_list\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, VectorAssembler, MinMaxScaler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa284b47-d962-47a9-b990-5bbfaeaff070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"sparkXGBoost\") \\\n",
    "    .getOrCreate()\n",
    "mlflow.autolog(disable=True)\n",
    "mlflow.spark.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c84e855-ddbe-45c0-82c9-b005c7c0f5f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. 데이터로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb46cb5-c0a1-4072-963f-a6f9974d1175",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c20c36-c995-422e-9661-24d5b2075724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"`final`\"\n",
    "path = f\"{catalog}.{schema}\"\n",
    "\n",
    "try:\n",
    "    train = spark.read.table(f\"{path}.train_df\")\n",
    "    validation = spark.read.table(f\"{path}.validation_df\")\n",
    "    test = spark.read.table(f\"{path}.test_df\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data from Unity Catalog Volume: {e}\")\n",
    "# display(train)\n",
    "# display(validation)\n",
    "# display(test)\n",
    "\n",
    "train = train.withColumn(\"label\", when(train[\"rating\"] >= 4, 1).otherwise(0))\n",
    "validation = validation.withColumn(\"label\", when(validation[\"rating\"] >= 4, 1).otherwise(0))\n",
    "test = test.withColumn(\"label\", when(test[\"rating\"] >= 4, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b61419d-82ed-4b67-9ee2-700bfcdd01a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96a9659d-6f72-4d65-b112-ba1ab26c033f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### IMDB 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b4db14-6319-4e29-ae78-ebed6d258de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"`imdb`\"\n",
    "imdb_path = f\"{catalog}.{schema}\"\n",
    "\n",
    "try:\n",
    "    imdb_ratings = spark.read.table(f\"{imdb_path}.title_ratings\")\n",
    "    print(\"Data loaded successfully from Unity Catalog Volume.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data from Unity Catalog Volume: {e}\")\n",
    "    print(f\"Please ensure CSV files (imdb_ratings.csv) exist in {imdb_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dd78242-4c3f-499c-b9de-b0d0ffe62988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. 데이터분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66a39b18-7335-4eff-a3fa-0e6f4864f6c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3ce0016-1734-4b33-ace4-6010f3075ad3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"genres\", outputCol=\"genres_tokens\", pattern=\"\\\\|\")\n",
    "vectorizer = CountVectorizer(inputCol=\"genres_tokens\", outputCol=\"genres_vec\")\n",
    "# assembler_numvotes = VectorAssembler(inputCols=[\"numVotes\"], outputCol=\"numVotes_vec\")\n",
    "# scaler = MinMaxScaler(inputCol=\"numVotes_vec\", outputCol=\"numVotes_scaled\")\n",
    "user_indexer = StringIndexer(inputCol=\"userId\", outputCol=\"userIndex\")\n",
    "user_indexer_model = user_indexer.fit(train)\n",
    "movie_indexer = StringIndexer(inputCol=\"movieId\", outputCol=\"movieIndex\")\n",
    "\n",
    "assembler_all = VectorAssembler(\n",
    "    # inputCols=[\"genres_vec\", \"averageRating\", \"numVotes_scaled\", \"userIndex\", \"movieIndex\", \"year\"],\n",
    "    inputCols=[\"genres_vec\", \"userIndex\", \"movieIndex\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    # tokenizer, vectorizer, assembler_numvotes, scaler,\n",
    "    # user_indexer, movie_indexer, assembler_all\n",
    "    tokenizer, vectorizer, \n",
    "    user_indexer, movie_indexer, assembler_all\n",
    "])\n",
    "\n",
    "pipeline_model = pipeline.fit(train)\n",
    "train_transformed = pipeline_model.transform(train)\n",
    "validation_transformed = pipeline_model.transform(validation)\n",
    "test_transformed = pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60d3462b-9e09-41eb-9fde-0de769558505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data_with_val = train_transformed.withColumn(\"validationIndicator\", lit(0))\n",
    "validation_data_with_val = validation_transformed.withColumn(\"validationIndicator\", lit(1))\n",
    "train_val_union = train_data_with_val.union(validation_data_with_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c41418dd-1adf-4548-a228-9ef00c6a3a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. 모델 설계 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3351bff2-1c8f-414d-8f7c-2235638d1670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 평가지표 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85914ef9-eaa4-4aec-9474-a5de7fea1b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Precision@K 계산 함수\n",
    "def precision_at_k(df: pd.DataFrame, k: int = 5, threshold: float = 4.0) -> float:\n",
    "    top_k = (\n",
    "        df.sort_values([\"userIndex\", \"y_pred_proba\"], ascending=[True, False])\n",
    "        .groupby(\"userIndex\")\n",
    "        .head(k)\n",
    "    )\n",
    "    top_k[\"hit\"] = (top_k[\"y_true\"] >= threshold).astype(int)\n",
    "    user_precision = top_k.groupby(\"userIndex\")[\"hit\"].mean()\n",
    "    return user_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee7b37b3-b8bf-46ab-823d-288e6388afab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def recall_at_k(df: pd.DataFrame, k: int = 5, threshold: float = 4.0) -> float:\n",
    "    # 사용자별 실제 긍정(평점 >= threshold) 아이템 수\n",
    "    user_positive_counts = df[df[\"y_true\"] >= threshold].groupby(\"userIndex\").size()\n",
    "\n",
    "    # 사용자별 top-k 추천 추출\n",
    "    top_k = (\n",
    "        df.sort_values([\"userIndex\", \"y_pred_proba\"], ascending=[True, False])\n",
    "        .groupby(\"userIndex\")\n",
    "        .head(k)\n",
    "        .copy()\n",
    "    )\n",
    "    top_k[\"hit\"] = (top_k[\"y_true\"] >= threshold).astype(int)\n",
    "\n",
    "    # 사용자별 top-k 추천에서 맞춘 아이템 수\n",
    "    user_hits = top_k.groupby(\"userIndex\")[\"hit\"].sum()\n",
    "\n",
    "    # 사용자별 recall 계산 (실제 긍정 아이템 수가 0인 경우 제외)\n",
    "    recall_per_user = user_hits / user_positive_counts\n",
    "    recall_per_user = recall_per_user.dropna()  # NaN 처리 (실제 긍정 아이템이 없는 사용자 제외)\n",
    "\n",
    "    # 전체 사용자 평균 Recall@K 반환\n",
    "    return recall_per_user.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adac5c51-4f58-466c-a8f5-c38462e79611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ndcg_at_k(df: pd.DataFrame, k: int = 10) -> float:\n",
    "    def dcg(relevances):\n",
    "        return np.sum((2**relevances - 1) / np.log2(np.arange(2, relevances.size + 2)))\n",
    "\n",
    "    ndcgs = []\n",
    "\n",
    "    for user, group in df.groupby(\"userIndex\"):\n",
    "        # user별 y_pred_proba 기준 내림차순 정렬, top-k 추출\n",
    "        top_k = group.sort_values(\"y_pred_proba\", ascending=False).head(k)\n",
    "        rel = top_k[\"y_true\"].values\n",
    "        \n",
    "        # 이상적인 순서(내림차순 y_true 정렬)\n",
    "        ideal_rel = np.sort(group[\"y_true\"].values)[::-1][:k]\n",
    "        \n",
    "        actual_dcg = dcg(rel)\n",
    "        ideal_dcg = dcg(ideal_rel)\n",
    "\n",
    "        ndcg = actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3f9a08-fbea-4caf-a2f8-a2bcbc8eb528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## XgbClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3d5f30b-860d-4e0b-b96e-503c79ac1921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 모델 설계 및 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c695f2b-6659-413d-bff7-ab632b6a7e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xgb_model = SparkXGBClassifier(\n",
    "    max_depth=6,\n",
    "    num_round=100,\n",
    "    eta=0.1,\n",
    "    early_stopping_rounds=50,\n",
    "    eval_metric='logloss',\n",
    "    missing=0.0,  # NaN 처리 방식\n",
    "    features_col=\"features\",\n",
    "    label_col=\"label\",\n",
    "    prediction_col=\"prediction\",\n",
    "    probability_col=\"probability\",\n",
    "    seed=0,\n",
    "    validation_indicator_col=\"validationIndicator\"\n",
    ")\n",
    "\n",
    "# 2. 학습\n",
    "xgb_model_fitted = xgb_model.fit(train_val_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccdd70f0-029f-4a3d-89a6-7f27fbbe9418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_val_union.select(\"validationIndicator\").distinct().show()\n",
    "train_val_union.select(\"validationIndicator\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12194c96-dfb3-4215-b9ae-845cf192c855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. 파티션 수 줄이기\n",
    "train_val_union = train_val_union.repartition(4)\n",
    "\n",
    "# 2. 단순한 모델 파라미터\n",
    "xgb_model = SparkXGBClassifier(\n",
    "    max_depth=6,\n",
    "    num_round=100,\n",
    "    eta=0.1,\n",
    "    features_col=\"features\",\n",
    "    label_col=\"label\",\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "# 3. 샘플 데이터로 실행 테스트 (예: 1000개)\n",
    "train_val_sample = train_val_union.limit(1000)\n",
    "\n",
    "xgb_model_fitted = xgb_model.fit(train_val_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b11ad3c7-7bf6-4e3e-8e6c-c1189921d30b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "train_data_with_val = train_transformed.withColumn(\"validationIndicator\", lit(0).cast(IntegerType()))\n",
    "validation_data_with_val = validation_transformed.withColumn(\"validationIndicator\", lit(1).cast(IntegerType()))\n",
    "\n",
    "train_val_union = train_data_with_val.union(validation_data_with_val)\n",
    "\n",
    "# 다시 사용하되, num_workers 명시\n",
    "xgb_model = SparkXGBClassifier(\n",
    "    max_depth=6,\n",
    "    num_round=100,\n",
    "    eta=0.1,\n",
    "    features_col=\"features\",\n",
    "    label_col=\"label\",\n",
    "    seed=0,\n",
    "    validation_indicator_col=\"validationIndicator\",\n",
    "    num_workers=2  # 꼭 명시\n",
    ")\n",
    "xgb_model_fitted = xgb_model.fit(train_val_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8582d4b-e9d5-4128-ac3e-5ba14e76b75c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. 예측\n",
    "predictions = xgb_model_fitted.transform(test_transformed)\n",
    "\n",
    "# 4. 확률값 추출 (예: Precision@K 등 평가용)\n",
    "predictions = predictions.withColumn(\"y_pred_proba\", col(\"probability\")[1]) \\\n",
    "                         .withColumnRenamed(\"label\", \"y_true\")\n",
    "\n",
    "# 5. Pandas로 변환 (위에서 사용한 평가지표 함수 사용 위해)\n",
    "test_pdf = predictions.select(\"userIndex\", \"movieIndex\", \"y_true\", \"prediction\", \"y_pred_proba\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5ab45d3-cc01-48a8-8d06-762cb7f40830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfe269c4-169c-4367-a003-9a2700009135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "p_at_10 = precision_at_k(test_pdf, k=10)\n",
    "print(f\"Precision@10: {p_at_10:.4f}\")\n",
    "\n",
    "r_at_10 = recall_at_k(test_pdf, k=10)\n",
    "print(f\"Recall@10: {r_at_10:.4f}\")\n",
    "\n",
    "ndcg_10 = ndcg_at_k(test_pdf, k=10)\n",
    "print(f\"NDCG@10: {ndcg_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ddc6716-89a5-47e0-8133-ed3e70fca7ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 사용자별 추천 영화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f2c48e1-7c54-44ee-a2c1-c93e0a7074f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "K = 10\n",
    "\n",
    "# 1. 사용자별 예측 상위 K개 영화 선택\n",
    "window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_proba\").desc())\n",
    "\n",
    "ranked = test_pred.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "                  .filter(col(\"rank\") <= K)\n",
    "\n",
    "# 2. 추천 영화 정보 묶기 (movieIndex와 예측 확률)\n",
    "ranked = ranked.withColumn(\"recommendation\", struct(col(\"movieIndex\").alias(\"movieId\"), col(\"y_pred_proba\").alias(\"pred_rating\")))\n",
    "\n",
    "# 3. 사용자별로 리스트로 그룹화\n",
    "recommendations = ranked.groupBy(\"userIndex\") \\\n",
    "    .agg(collect_list(\"recommendation\").alias(\"recommendations\")) \\\n",
    "    .orderBy(\"userIndex\")\n",
    "\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9da79c91-102b-45db-8e86-f587ba1b3390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "K = 10\n",
    "\n",
    "# 1. 영화 메타데이터에서 movieId와 title 추출\n",
    "# 예: movies라는 테이블이나 DataFrame이 있다고 가정\n",
    "movies_meta = train.select(\"movieId\", \"title\").dropDuplicates()\n",
    "\n",
    "# 2. test_pred에 title 붙이기 (movieId 기준 조인)\n",
    "test_with_title = test_pred.join(movies_meta, on=\"movieId\", how=\"left\")\n",
    "\n",
    "# 3. 사용자별 Top-K 추출\n",
    "window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_proba\").desc())\n",
    "\n",
    "ranked = test_with_title.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "                        .filter(col(\"rank\") <= K)\n",
    "\n",
    "# 4. 추천 항목에 title 포함하여 구조화\n",
    "ranked = ranked.withColumn(\n",
    "    \"recommendation\",\n",
    "    struct(\n",
    "        col(\"movieId\"),\n",
    "        col(\"title\"),\n",
    "        col(\"y_pred_proba\").alias(\"pred_rating\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. 사용자별 추천 리스트로 그룹화\n",
    "recommendations = ranked.groupBy(\"userIndex\") \\\n",
    "    .agg(collect_list(\"recommendation\").alias(\"recommendations\")) \\\n",
    "    .orderBy(\"userIndex\")\n",
    "\n",
    "# 6. 결과 확인\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe6508e-3f62-40ce-8b5f-1db17423b958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MLFlow + Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72b727f2-3085-4ea0-93ea-a1070b3bc698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 레이블 생성 (평점 4 이상은 1, 아니면 0)\n",
    "# Optuna 목적 함수 정의\n",
    "K = 10  # Precision@K 값\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"maxDepth\": trial.suggest_int(\"maxDepth\", 3, 10),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3),\n",
    "        \"numRound\": trial.suggest_int(\"numRound\", 50, 300),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"evalMetric\": \"logloss\",\n",
    "        \"earlyStoppingRounds\": 20,\n",
    "        \"numWorkers\": 4  # 작업자 수는 클러스터 환경에 맞게 조절\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(param)\n",
    "\n",
    "        model = SparkXGBClassifier(\n",
    "            featuresCol=\"features\",  # VectorAssembler로 만든 feature 컬럼명\n",
    "            labelCol=\"label\",\n",
    "            **param\n",
    "        )\n",
    "\n",
    "       # 모델 학습 (evalSets에 검증 데이터 전달)\n",
    "        model = model.fit(train_df, evalSets=[valid_df])\n",
    "\n",
    "        # 테스트 데이터 예측\n",
    "        pred_test = model.transform(test_df)\n",
    "\n",
    "        # positive 클래스 확률 추출 (probability 컬럼에서 [1])\n",
    "\n",
    "        extract_prob = udf(lambda v: float(v[1]), DoubleType())\n",
    "        pred_test = pred_test.withColumn(\"y_pred_prob\", extract_prob(col(\"probability\")))\n",
    "\n",
    "        # Precision@K 계산\n",
    "        window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_prob\").desc())\n",
    "        top_k = pred_test.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= K)\n",
    "\n",
    "        # 평점 4 이상을 positive (1)로 변환\n",
    "        top_k = top_k.withColumn(\"y_true\", (col(\"rating\") >= 4).cast(\"int\"))\n",
    "\n",
    "        precision_df = top_k.groupBy(\"userIndex\").agg({\"y_true\": \"avg\"})\n",
    "        avg_precision_at_k = precision_df.selectExpr(\"avg(`avg(y_true)`) as precision_at_k\").collect()[0][\"precision_at_k\"]\n",
    "\n",
    "        mlflow.log_metric(\"precision_at_k\", avg_precision_at_k)\n",
    "        mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "        # Optuna는 최소화만 지원하므로 음수 반환\n",
    "        return -avg_precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f5baedf-abff-49b9-9002-f255e082551e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optuna study 실행\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 최적 모델 학습 및 저장\n",
    "best_model = XGBClassifier(**study.best_params)\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=20, verbose=False)\n",
    "\n",
    "with mlflow.start_run(run_name=\"final_best_model\"):\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.sklearn.log_model(best_model, \"final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "336a1e5e-b149-4b35-b47b-81765882f8c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 5. 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15903bf-26d8-4ccb-bc6e-02739385b5a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5-1. 안 본 영화 중에서 추천(rating 있다면 본 영화로 판단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03fed727-1895-43aa-85a1-83e5a09c2920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. 사용자별 본 영화 집합 생성 (train_pd, validation_pd 기반 Spark DF로 변환 필요)\n",
    "# 만약 train_df, valid_df가 Spark DF라면 바로 사용 가능\n",
    "seen_movies_df = train_df.select(\"userIndex\", \"movieIndex\") \\\n",
    "    .union(valid_df.select(\"userIndex\", \"movieIndex\")) \\\n",
    "    .distinct() \\\n",
    "    .groupBy(\"userIndex\") \\\n",
    "    .agg(collect_set(\"movieIndex\").alias(\"seen_movies\"))\n",
    "\n",
    "# 2. test_pred: 예측 결과가 담긴 Spark DataFrame (컬럼: userIndex, movieIndex, y_pred_prob)\n",
    "# test_pred와 seen_movies_df를 userIndex 기준으로 조인\n",
    "test_pred_filtered = test_pred.join(seen_movies_df, on=\"userIndex\", how=\"left_outer\")\n",
    "\n",
    "# 3. 이미 본 영화 제외 필터링 (seen_movies가 null일 수도 있으므로 null-safe)\n",
    "test_pred_filtered = test_pred_filtered.filter(\n",
    "    (col(\"seen_movies\").isNull()) | (~array_contains(col(\"seen_movies\"), col(\"movieIndex\")))\n",
    ")\n",
    "\n",
    "# 4. 추천 상위 K개 추출\n",
    "window_spec = Window.partitionBy(\"userIndex\").orderBy(col(\"y_pred_prob\").desc())\n",
    "\n",
    "ranked = test_pred_filtered.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "                           .filter(col(\"rank\") <= K)\n",
    "\n",
    "# 5. 추천 결과 컬럼 생성 (movieId, pred_rating 구조체)\n",
    "ranked = ranked.withColumn(\n",
    "    \"recommendation\",\n",
    "    struct(col(\"movieIndex\").alias(\"movieId\"), col(\"y_pred_prob\").alias(\"pred_rating\"))\n",
    ")\n",
    "\n",
    "# 6. 사용자별 추천 리스트 생성\n",
    "recommendations = ranked.groupBy(\"userIndex\") \\\n",
    "                        .agg(collect_list(\"recommendation\").alias(\"recommendations\")) \\\n",
    "                        .orderBy(\"userIndex\")\n",
    "\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c358f4c5-fd3b-4f32-ba22-5d9de4da1e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5-2. 추가 User가 들어왔을때 어떤 영화를 추천할지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3718f019-6ea2-41ec-8933-43a29bdeadd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. 신규유저에 영화정보를 바탕으로 기존유저와 매칭\n",
    "\n",
    "2. 새로운 user_index 추천하지 않음(새로 학습해야함) - 현재 모델에서 user_index가 중요한 역할/ 처음 보는 User_index보고 엉뚱한 예측할 확률 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fee224e-92a9-4de2-ac4f-75235d197416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Cold Start 유저 처리\n",
    "신규 유저:\n",
    "\n",
    "A안: userIndex 제거한 일반 모델로 추천 제공 (장르, 평균 평점 기반)\n",
    "\n",
    "B안: 기존 유저와 유사도 기반으로 매칭 → 그 유저의 추천을 가져옴 (collaborative filtering 유사)\n",
    "\n",
    "2. 데이터 업데이트 및 재학습\n",
    "신규 rating이 수집되면 데이터에 추가\n",
    "\n",
    "일정 주기 (일간/주간 등)에 따라 모델 재학습\n",
    "\n",
    "재학습된 모델은 최신화된 추천 반영 가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2ebbe93-2b8f-4de8-890e-c215532cc734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. 시청 영화 바탕으로 유사한 기존 유저 indexr를 찾고,\n",
    "2. 그 indexr와 시청 영화 바탕으로 추천 영화 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c576c02a-1857-4abe-9e70-7b940939a29e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1. 신규 유저가 본 영화 리스트 (Python set으로 준비)\n",
    "new_user_seen_movies = [1, 10, 50, 300]\n",
    "new_user_set = set(new_user_seen_movies)\n",
    "\n",
    "# Step 2. 기존 유저별 시청 영화 집합 생성 (ratings는 Spark DataFrame)\n",
    "user_movie_sets = ratings.groupBy(\"userId\").agg(collect_set(\"movieId\").alias(\"movie_set\"))\n",
    "\n",
    "# Step 3. Jaccard 유사도 계산 함수 정의 및 UDF 등록\n",
    "def jaccard_similarity(movies):\n",
    "    movies_set = set(movies) if movies is not None else set()\n",
    "    intersection = len(new_user_set.intersection(movies_set))\n",
    "    union = len(new_user_set.union(movies_set))\n",
    "    return float(intersection) / union if union != 0 else 0.0\n",
    "\n",
    "jaccard_udf = udf(jaccard_similarity, DoubleType())\n",
    "\n",
    "# Step 4. 각 유저별 Jaccard 유사도 계산 후 내림차순 정렬, 최상위 1명 추출\n",
    "similar_users = user_movie_sets.withColumn(\"jaccard_sim\", jaccard_udf(col(\"movie_set\"))) \\\n",
    "                               .orderBy(desc(\"jaccard_sim\")) \\\n",
    "                               .limit(1)\n",
    "\n",
    "# Step 5. 가장 유사한 유저의 userId 추출\n",
    "top_user_id = similar_users.select(\"userId\").first()[\"userId\"]\n",
    "\n",
    "# Step 6. user_indexer_model을 이용해 userIndex 변환 (userId -> userIndex)\n",
    "top_user_index = user_indexer_model.transform(\n",
    "    spark.createDataFrame([(top_user_id,)], [\"userId\"])\n",
    ").select(\"userIndex\").first()[\"userIndex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74601779-6f8e-4c38-a3be-74da9af315aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 5. 전체 영화 목록에서 신규 유저가 보지 않은 영화만 필터링\n",
    "unseen_movies_df = df_cleaned.filter(~col(\"movieId\").isin(new_user_seen_movies))\n",
    "\n",
    "# Step 6. 추천 후보 영화에 대해 pipeline_model 변환 (movieIndex, features 등 생성)\n",
    "unseen_features_df = pipeline_model.transform(unseen_movies_df)\n",
    "\n",
    "# Step 7. 유사한 기존 유저의 userIndex를 모든 행에 추가\n",
    "unseen_features_df = unseen_features_df.withColumn(\"userIndex\", lit(top_user_index))\n",
    "\n",
    "# 중복 movieId 제거\n",
    "unseen_features_unique_df = unseen_features_df.dropDuplicates([\"movieId\"])\n",
    "\n",
    "# Step 8. features 컬럼을 numpy 배열로 변환 (pandas 변환 후 toArray 사용)\n",
    "pdf_unseen = unseen_features_unique_df.select(\"features\", \"movieId\", \"title\").toPandas()\n",
    "X_unseen = np.vstack(pdf_unseen[\"features\"].apply(lambda v: v.toArray()))\n",
    "\n",
    "# Step 9. 모델 예측 (XGBClassifier 또는 XGBRegressor에 따라 predict 또는 predict_proba 사용)\n",
    "# 여기서는 분류 문제인 경우로 가정해 predict_proba 사용, 클래스 1 확률 추출\n",
    "y_pred_proba = model.predict_proba(X_unseen)[:, 1]\n",
    "\n",
    "# Step 10. 예측 결과를 pandas DataFrame에 추가\n",
    "pdf_unseen[\"prediction\"] = y_pred_proba\n",
    "\n",
    "# Step 11. 예측 상위 K개 추천 추출 (K=10)\n",
    "top_k = pdf_unseen.sort_values(by=\"prediction\", ascending=False).head(10)\n",
    "\n",
    "# 결과 출력\n",
    "print(top_k[[\"movieId\", \"title\", \"prediction\"]])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7760516635777470,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) 1. 전체 XGboost_imdb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
