{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0745aa6b-eb43-47d4-b271-460d65c67331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. 알고리즘 설명\n",
    "\n",
    "이 추천 시스템은 크게 두 가지 알고리즘을 혼합하여 사용합니다.\n",
    "\n",
    "### 1.1. 콘텐츠 기반 필터링 (Content-Based Filtering)\n",
    "\n",
    "-   **원리**: 사용자가 과거에 선호했던(혹은 현재 입력한) 아이템(영화)의 속성(장르)을 분석하여, 그와 유사한 속성을 가진 다른 아이템을 추천하는 방식입니다.\n",
    "-   **핵심 기술 (TF-IDF 및 코사인 유사도)**:\n",
    "    -   **TF-IDF (Term Frequency-Inverse Document Frequency)**: 영화의 '장르(genres)' 데이터를 벡터화하는 데 사용됩니다. 특정 장르(단어)가 한 영화(문서) 내에서 얼마나 자주 나타나는지(TF)와 전체 영화 데이터셋에서 얼마나 희귀하게 나타나는지(IDF)를 고려하여 장르의 중요도를 측정합니다. 이를 통해 각 영화를 장르 특징을 나타내는 벡터로 변환합니다.\n",
    "    -   **코사인 유사도 (Cosine Similarity)**: TF-IDF로 벡터화된 영화들 간의 유사도를 측정하는 데 사용됩니다. 두 영화 벡터 간의 코사인 값(각도)을 계산하여, 각도가 작을수록(코사인 값이 1에 가까울수록) 두 영화의 장르가 비슷하다고 판단하고, 유사한 영화로 간주합니다.\n",
    "\n",
    "### 1.2. 인기/고평점 영화 추천 (Popular/High-Rated Recommendations)\n",
    "\n",
    "-   **원리**: 단순히 많은 사용자에게 인기가 많거나 평균 평점이 높은 영화를 추천하는 방식입니다.\n",
    "-   **활용**: 콘텐츠 기반 추천만으로는 새로운 사용자나 취향이 뚜렷하지 않은 사용자에게 적합하지 않을 수 있으며, 추천 다양성이 부족할 수 있습니다. 이를 보완하기 위해 최소 평점 수(num_ratings)를 기준으로 하여 평균 평점(avg_rating)이 높은 영화를 우선적으로 추천 목록에 포함시킵니다. 이는 '탐색(Exploration)'과 '활용(Exploitation)'의 균형을 맞추는 역할을 합니다.\n",
    "\n",
    "### 1.3. 혼합 추천 전략\n",
    "\n",
    "이 시스템은 다음 순서로 추천 목록을 구성합니다.\n",
    "\n",
    "1.  사용자가 지정한 `num_guaranteed_popular`만큼 **리뷰가 많고 평점이 높은 인기 영화**를 무조건 추천 목록에 포함합니다. (중복 및 사용자가 이미 입력한 영화는 제외)\n",
    "2.  나머지 추천 개수를 채우기 위해, 사용자가 입력한 영화들을 기반으로 **콘텐츠 기반 유사 영화**를 찾아 추천합니다.\n",
    "3.  만약 1, 2단계를 거치고도 최종 추천 개수(num_recommendations_total)가 부족하면, **추가적인 인기/고평점 영화**로 목록을 채웁니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7361a271-d7aa-4591-8fd4-de049d4335c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 2. 코드 작동 순서\n",
    "\n",
    "### 2.1. 1단계: 라이브러리 임포트\n",
    "\n",
    "-   `pandas`, `numpy`: 데이터 처리 및 조작을 위한 핵심 라이브러리입니다.\n",
    "-   `sklearn.feature_extraction.text.TfidfVectorizer`: 텍스트 데이터를 TF-IDF 벡터로 변환합니다.\n",
    "-   `sklearn.metrics.pairwise.linear_kernel`: 코사인 유사도(선형 커널)를 효율적으로 계산합니다.\n",
    "-   `sklearn.model_selection.train_test_split`: 데이터셋을 훈련 세트와 테스트 세트로 분할합니다.\n",
    "-   `sklearn.metrics.precision_score`, `recall_score`, `f1_score`: 추천 시스템 성능 평가 지표를 계산합니다.\n",
    "-   `matplotlib.pyplot`, `seaborn`: 데이터 시각화를 위한 라이브러리입니다.\n",
    "-   `pyspark.sql.SparkSession`, `pyspark.sql.functions`, `pyspark.sql.types`: Databricks 환경에서 Spark 데이터프레임 작업을 위한 라이브러리입니다.\n",
    "\n",
    "### 2.2. 2단계: 데이터 로드\n",
    "\n",
    "-   `SparkSession`을 초기화합니다. Databricks에서는 대부분 자동 초기화됩니다.\n",
    "-   **Unity Catalog**의 `'1dt_team8_managed'.'movielens-small'.movies`와 `'1dt_team8_managed'.'movielens-small'.ratings` 테이블에서 영화 및 평점 데이터를 로드합니다.\n",
    "-   Unity Catalog 로드에 실패하면, `/databricks-datasets/movielens/small/` 경로에 있는 CSV 파일에서 데이터를 로드하도록 폴백(fallback) 로직이 구현되어 있습니다.\n",
    "-   콘텐츠 기반 추천을 위해 `movies_df_spark`와 `ratings_df_spark` (Spark DataFrame)를 `toPandas()`를 사용하여 `movies_df`와 `ratings_df` (Pandas DataFrame)로 변환합니다. 이는 TF-IDF 및 코사인 유사도 계산이 Pandas DataFrame에서 더 효율적이기 때문입니다.\n",
    "\n",
    "### 2.3. 3단계: 데이터 전처리 및 콘텐츠 기반 추천 시스템 구축\n",
    "\n",
    "-   **장르 데이터 클리닝**: `movies_df`의 `genres` 컬럼에 있는 누락된 값(NaN)을 빈 문자열('')로 채웁니다.\n",
    "-   **TF-IDF 벡터화**: `TfidfVectorizer`를 사용하여 `movies_df['genres']` 컬럼의 텍스트 데이터를 TF-IDF 행렬(`tfidf_matrix`)로 변환합니다. `stop_words='english'`를 사용하여 일반적인 영어 불용어(예: 'a', 'the')를 제거합니다.\n",
    "-   **코사인 유사도 계산**: `linear_kernel` 함수를 사용하여 `tfidf_matrix`로부터 모든 영화 쌍 간의 코사인 유사도를 계산하여 `cosine_sim` 행렬을 생성합니다. 이 행렬의 각 셀 `(i, j)`는 `i`번째 영화와 `j`번째 영화 간의 유사도를 나타냅니다.\n",
    "-   **영화 인덱스 매핑**: 영화 제목을 기준으로 영화의 인덱스를 빠르게 찾을 수 있도록 `indices` Pandas Series를 생성합니다.\n",
    "-   **헬퍼 함수 정의**:\n",
    "    -   `get_title_from_id(movie_id)`: 영화 ID를 입력받아 해당 영화의 제목을 반환합니다.\n",
    "    -   `get_movie_ids_from_names(movie_names)`: 영화 이름 리스트를 입력받아 해당 영화들의 ID 리스트를 반환하고, 찾을 수 없는 영화 이름도 반환합니다.\n",
    "\n",
    "### 2.4. 4단계: 추천 함수 정의\n",
    "\n",
    "-   `get_content_based_recommendations(movie_id, cosine_sim_matrix, movies_df_local, indices_local, num_recommendations)`:\n",
    "    -   특정 `movie_id`를 기반으로 `cosine_sim_matrix`를 사용하여 가장 유사한 `num_recommendations`개의 영화를 찾아 Pandas DataFrame 형태로 반환합니다.\n",
    "    -   입력 영화 자신은 추천 목록에서 제외합니다.\n",
    "-   `recommend_movies_by_input(user_movie_ids, num_popular_or_high_rated_fixed, num_recommendations_total)`:\n",
    "    -   사용자가 입력한 `user_movie_ids`를 기반으로 최종 `num_recommendations_total`개의 영화를 추천하는 메인 함수입니다.\n",
    "    -   내부적으로 Spark DataFrame `ratings_df_spark`를 사용하여 영화별 `num_ratings`(리뷰 수)와 `avg_rating`(평균 평점)을 계산합니다.\n",
    "    -   `min_ratings_threshold` (기본값 50) 이상의 리뷰를 가진 영화 중에서 평점이 높은 순서로 `num_popular_or_high_rated_fixed` 개수만큼의 인기 영화를 먼저 추가합니다.\n",
    "    -   남은 추천 개수를 채우기 위해, 입력된 `user_movie_ids` 각각에 대해 `get_content_based_recommendations`를 호출하여 콘텐츠 기반 유사 영화를 가져와 추가합니다.\n",
    "    -   마지막으로, 최종 추천 목록의 개수가 `num_recommendations_total`에 미달하면, 추가적인 인기/고평점 영화로 목록을 채웁니다.\n",
    "    -   모든 추천이 완료되면, 추천 목록에서 사용자가 이미 입력한 영화와 중복된 영화를 제거하고, 최종 목록을 Spark DataFrame으로 변환하여 반환합니다. 이는 Databricks `display` 함수와의 호환성을 높입니다.\n",
    "\n",
    "### 2.5. 5단계: 모델 테스트 (사용자 입력)\n",
    "\n",
    "-   사용자에게 추천받고 싶은 영화의 이름 또는 ID를 3~5개 쉼표로 구분하여 입력하도록 요청합니다.\n",
    "-   입력된 값이 숫자로만 구성되어 있으면 ID로, 그렇지 않으면 이름으로 간주합니다.\n",
    "-   입력된 영화 이름/ID가 시스템에 존재하는지 확인하고, 유효한 입력이 들어올 때까지 반복하여 입력을 받습니다.\n",
    "-   `recommend_movies_by_input` 함수를 호출하여 `num_recommendations_output` (총 추천 개수)와 `num_guaranteed_popular` (필수 포함 인기 영화 개수)를 조절하여 영화를 추천받습니다.\n",
    "-   최종 추천된 영화 목록(제목과 장르)을 Databricks의 `display` 함수를 사용하여 출력합니다.\n",
    "\n",
    "### 2.6. 6단계: 모델 성능 평가 및 시각화 (주석 처리됨)\n",
    "\n",
    "-   `evaluate_recommender` 함수는 추천 시스템의 성능을 대략적으로 측정하기 위한 함수입니다.\n",
    "    -   `ratings_df`를 훈련 세트(`train_ratings`)와 테스트 세트(`test_ratings`)로 분할합니다.\n",
    "    -   테스트 세트에서 임의의 사용자(`sample_users`)를 샘플링합니다.\n",
    "    -   각 샘플링된 사용자에 대해, 훈련 데이터에서 높은 평점을 준 영화들을 '입력 영화'로 가정하고 추천을 수행합니다.\n",
    "    -   테스트 데이터에서 해당 사용자가 실제로 높은 평점을 준 영화(`actual_relevant_movie_ids`)와 추천된 영화(`recommended_movie_ids`)를 비교하여 **Precision (정밀도)**, **Recall (재현율)**, **F1-Score**를 계산합니다.\n",
    "    -   이 평가 지표들은 추천 시스템이 얼마나 정확하고 포괄적으로 관련 영화를 추천하는지를 나타냅니다.\n",
    "-   `model_performance_evaluation()` 함수는 `evaluate_recommender`를 호출하고, 계산된 평균 Precision, Recall, F1-Score를 출력합니다.\n",
    "-   `matplotlib`과 `seaborn`을 사용하여 이러한 성능 지표를 막대 그래프로 시각화합니다.\n",
    "-   **참고**: 현재 코드에서는 `model_performance_evaluation()` 함수가 주석 처리되어 있어 실행되지 않습니다. 평가를 원한다면 주석을 해제해야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f4392f4d-ecd9-4ceb-8026-ed40f5d1d533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Microsoft Azure Databricks Notebook.\n",
    "# Content-Based + 인기 영화 추천 시스템 (Hybrid)\n",
    "\n",
    "# 1. 라이브러리 임포트\n",
    "import pandas as pd # 데이터 처리 및 조작을 위한 필수 라이브러리\n",
    "import numpy as np # 수치 계산을 위한 라이브러리 (pandas와 함께 사용)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 텍스트 데이터를 TF-IDF 특징 벡터로 변환\n",
    "from sklearn.metrics.pairwise import linear_kernel # 코사인 유사도(선형 커널)를 효율적으로 계산\n",
    "from sklearn.model_selection import train_test_split # 데이터셋을 훈련 세트와 테스트 세트로 분할\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score # 추천 시스템 성능 평가 지표 (정밀도, 재현율, F1-점수)\n",
    "import matplotlib.pyplot as plt # 데이터 시각화를 위한 라이브러리\n",
    "import seaborn as sns # matplotlib 기반의 통계 데이터 시각화 라이브러리\n",
    "from pyspark.sql import SparkSession # Spark 애플리케이션의 진입점 (Spark DataFrame 사용에 필수)\n",
    "from pyspark.sql.functions import col, lit, count, avg, desc, udf # Spark DataFrame 컬럼 조작 함수 및 사용자 정의 함수(UDF)\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType # Spark DataFrame 스키마 정의를 위한 데이터 타입\n",
    "\n",
    "# Spark 세션 초기화 (Databricks에서는 자동으로 초기화되지만 명시적으로 정의 가능)\n",
    "# getOrCreate()는 이미 세션이 존재하면 기존 세션을 반환하고, 없으면 새로 생성합니다.\n",
    "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
    "\n",
    "# 2. 데이터 로드 (Unity Catalog 테이블에서 불러오도록 변경)\n",
    "# '1dt_team8_managed.movielens-small' 데이터베이스에 movies, ratings 테이블이 있다고 가정합니다.\n",
    "try:\n",
    "    # Unity Catalog에서 movies 및 ratings 테이블을 Spark DataFrame으로 직접 읽어옵니다.\n",
    "    # 이 방식은 Databricks 환경에서 최신 데이터 거버넌스 및 접근 방식을 따릅니다.\n",
    "    movies_df_spark = spark.read.table(\"`1dt_team8_databricks`.`movielens-small`.movies\")\n",
    "    ratings_df_spark = spark.read.table(\"`1dt_team8_databricks`.`movielens-small`.ratings\")\n",
    "    print(\"데이터를 Unity Catalog 테이블에서 성공적으로 불러왔습니다.\")\n",
    "except Exception as e:\n",
    "    # Unity Catalog 로드 실패 시, 기존의 /databricks-datasets 경로에서 CSV 파일을 로드합니다.\n",
    "    # 이는 개발 또는 테스트 환경에서 데이터 접근에 문제가 있을 경우를 대비한 폴백(fallback) 로직입니다.\n",
    "    print(f\"Unity Catalog 테이블 로드 중 오류 발생: {e}\")\n",
    "    print(\"기존 경로 변수 방식으로 시도합니다. (데이터 경로를 다시 확인해주세요)\")\n",
    "    movies_path = \"/databricks-datasets/movielens/small/movies.csv\"\n",
    "    ratings_path = \"/databricks-datasets/movielens/small/ratings.csv\"\n",
    "    movies_df_spark = spark.read.csv(movies_path, header=True, inferSchema=True) # CSV 파일 로드 (첫 줄은 헤더, 스키마 자동 추론)\n",
    "    ratings_df_spark = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
    "\n",
    "# Pandas DataFrame으로 변환 (콘텐츠 기반 추천을 위해 TF-IDF를 사용하기 위함)\n",
    "# scikit-learn 라이브러리는 주로 Pandas DataFrame에서 작동하므로 Spark DataFrame을 변환합니다.\n",
    "# 대규모 데이터셋의 경우 이 변환 대신 Spark MLlib (Spark의 기계 학습 라이브러리) 사용을 고려해야 합니다.\n",
    "# Spark MLlib은 분산 처리를 통해 대용량 데이터에서도 TF-IDF 및 유사도 계산을 수행할 수 있습니다.\n",
    "movies_df = movies_df_spark.toPandas()\n",
    "ratings_df = ratings_df_spark.toPandas()\n",
    "\n",
    "# 데이터 확인 (주석 처리됨)\n",
    "# print(\"Movies DataFrame head:\")\n",
    "# print(movies_df.head()) # movies DataFrame의 첫 5행 출력\n",
    "# print(\"\\nRatings DataFrame head:\")\n",
    "# print(ratings_df.head()) # ratings DataFrame의 첫 5행 출력\n",
    "\n",
    "# 3. 데이터 전처리 및 콘텐츠 기반 추천 시스템 구축\n",
    "\n",
    "# 장르 데이터 클리닝 및 TF-IDF 벡터화\n",
    "# genres 컬럼의 누락된 값 처리 (결측치는 빈 문자열로 대체하여 TF-IDF 변환 시 오류 방지)\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "\n",
    "# TfidfVectorizer 객체 생성: 텍스트(장르 문자열)를 TF-IDF 특징 벡터로 변환합니다.\n",
    "# stop_words='english'를 설정하여 영어 불용어(예: \"and\", \"the\")를 벡터화에서 제외합니다.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# fit_transform: genres 컬럼의 모든 영화 장르를 학습하고(fit), 이를 TF-IDF 행렬로 변환합니다(transform).\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df['genres'])\n",
    "\n",
    "print(f\"\\nTF-IDF matrix shape: {tfidf_matrix.shape}\") # 생성된 TF-IDF 행렬의 차원 출력 (영화 수, 고유 장르 특징 수)\n",
    "\n",
    "# 코사인 유사도 계산 (콘텐츠 기반 유사도)\n",
    "# linear_kernel: 두 벡터 세트의 내적을 계산하여 코사인 유사도를 효율적으로 구합니다.\n",
    "# 여기서는 tfidf_matrix 자기 자신과의 유사도를 계산하여 모든 영화 쌍 간의 유사도 행렬을 만듭니다.\n",
    "# 결과인 cosine_sim은 N x N 행렬이며, 여기서 N은 영화의 수입니다.\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 영화 제목과 인덱스를 매핑하는 시리즈 생성\n",
    "# 영화 제목을 입력받았을 때 해당 영화의 pandas DataFrame 인덱스를 빠르게 찾기 위해 사용됩니다.\n",
    "# drop_duplicates()는 중복된 영화 제목이 있을 경우 첫 번째 인덱스만 유지합니다.\n",
    "indices = pd.Series(movies_df.index, index=movies_df['title']).drop_duplicates()\n",
    "\n",
    "# 영화 ID로 제목을 찾는 헬퍼 함수 (Pandas DataFrame 사용)\n",
    "def get_title_from_id(movie_id):\n",
    "    \"\"\"\n",
    "    주어진 영화 ID에 해당하는 영화 제목을 movies_df에서 찾아 반환합니다.\n",
    "    \"\"\"\n",
    "    if movie_id in movies_df['movieId'].values:\n",
    "        # movie_id가 일치하는 행을 찾아 'title' 컬럼의 첫 번째 값(iloc[0])을 반환\n",
    "        return movies_df[movies_df['movieId'] == movie_id]['title'].iloc[0]\n",
    "    return None # 해당 ID의 영화가 없으면 None 반환\n",
    "\n",
    "# 영화 이름으로 ID를 찾는 헬퍼 함수 (Pandas DataFrame 사용)\n",
    "def get_movie_ids_from_names(movie_names):\n",
    "    \"\"\"\n",
    "    주어진 영화 이름 리스트에 해당하는 영화 ID들을 찾아 반환합니다.\n",
    "    찾을 수 없는 영화 이름도 별도로 반환합니다.\n",
    "    \"\"\"\n",
    "    found_ids = [] # 찾은 영화 ID들을 저장할 리스트\n",
    "    not_found_names = [] # 찾지 못한 영화 이름들을 저장할 리스트\n",
    "    for name in movie_names:\n",
    "        # 정확히 일치하는 제목 찾기 (대소문자 구분 없이 비교)\n",
    "        match = movies_df[movies_df['title'].str.lower() == name.lower()]\n",
    "        if not match.empty:\n",
    "            # 일치하는 영화가 있으면 해당 movieId를 추가\n",
    "            found_ids.append(match['movieId'].iloc[0])\n",
    "        else:\n",
    "            # 일치하는 영화가 없으면 not_found_names에 추가\n",
    "            not_found_names.append(name)\n",
    "    return found_ids, not_found_names # 찾은 ID와 찾지 못한 이름 리스트 반환\n",
    "\n",
    "\n",
    "# 4. 추천 함수 정의\n",
    "\n",
    "def get_content_based_recommendations(movie_id, cosine_sim_matrix, movies_df_local, indices_local, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    콘텐츠(장르) 기반으로 유사한 영화를 추천합니다. (movie_id 기반)\n",
    "\n",
    "    Args:\n",
    "        movie_id (int): 기준이 될 영화의 ID.\n",
    "        cosine_sim_matrix (np.array): 영화 간 코사인 유사도 행렬.\n",
    "        movies_df_local (pd.DataFrame): 영화 정보가 담긴 Pandas DataFrame.\n",
    "        indices_local (pd.Series): 영화 제목과 인덱스를 매핑하는 Series.\n",
    "        num_recommendations (int): 추천할 영화의 개수.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 추천된 영화들의 정보 (Pandas DataFrame).\n",
    "    \"\"\"\n",
    "    movie_title = get_title_from_id(movie_id) # 영화 ID로부터 제목을 가져옴\n",
    "    # 영화 제목이 없거나, 인덱스 매핑에 없는 경우 빈 DataFrame 반환 (유효하지 않은 입력)\n",
    "    if not movie_title or movie_title not in indices_local:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    idx = indices_local[movie_title] # 기준 영화의 인덱스를 가져옴\n",
    "    # 해당 영화의 유사도 점수 리스트를 가져옴 (enumerate로 인덱스와 점수 쌍 생성)\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "    # 유사도 점수를 기준으로 내림차순 정렬\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 자기 자신 제외: 첫 번째 요소(자기 자신과의 유사도 1.0)를 제외하고 상위 N개 선택\n",
    "    # num_recommendations + 1을 하는 이유는 자기 자신을 제외하고 원하는 개수를 얻기 위함\n",
    "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
    "    # 유사도 점수 리스트에서 영화 인덱스만 추출\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    # 해당 인덱스들의 영화 정보를 movies_df_local에서 가져와 반환\n",
    "    return movies_df_local.iloc[movie_indices]\n",
    "\n",
    "\n",
    "def recommend_movies_by_input(user_movie_ids, num_recommendations_total, num_popular_or_high_rated_fixed):\n",
    "    \"\"\"\n",
    "    사용자가 입력한 영화 ID를 기반으로 콘텐츠 기반 추천 + 인기/고평점 영화를 섞어서 추천합니다.\n",
    "    num_popular_or_high_rated_fixed 만큼 리뷰 많고 평점 높은 영화를 무조건 포함합니다.\n",
    "\n",
    "    Args:\n",
    "        user_movie_ids (list): 사용자가 입력한 영화 ID 리스트.\n",
    "        num_recommendations_total (int): 최종적으로 추천할 총 영화 개수.\n",
    "        num_popular_or_high_rated_fixed (int): 추천 목록에 무조건 포함할 인기/고평점 영화의 개수.\n",
    "\n",
    "    Returns:\n",
    "        pyspark.sql.DataFrame: 최종 추천된 영화들의 Spark DataFrame.\n",
    "    \"\"\"\n",
    "    recommended_movies = pd.DataFrame() # 추천된 영화들을 저장할 Pandas DataFrame (임시)\n",
    "    seen_movie_ids = set(user_movie_ids) # 사용자가 이미 입력한 영화 ID를 저장하여 추천 목록에서 제외\n",
    "\n",
    "    # --- 1. 리뷰 많고 평점 높은 영화 목록 미리 계산 (Spark DataFrame 사용) ---\n",
    "    # ratings_df_spark를 사용하여 영화별 리뷰 수(num_ratings)와 평균 평점(avg_rating)을 집계합니다.\n",
    "    movie_stats_df_spark = ratings_df_spark.groupBy(\"movieId\").agg(\n",
    "        count(col(\"rating\")).alias(\"num_ratings\"), # 각 영화의 리뷰 개수\n",
    "        avg(col(\"rating\")).alias(\"avg_rating\")     # 각 영화의 평균 평점\n",
    "    )\n",
    "\n",
    "    min_ratings_threshold = 50 # 최소 리뷰 수 임계값: 너무 적은 리뷰로 인한 평점 왜곡 방지\n",
    "    # 최소 리뷰 수를 만족하는 영화들만 필터링하고, 평균 평점, 리뷰 수 내림차순으로 정렬합니다.\n",
    "    # movies_df_spark와 조인하여 영화 제목 등의 정보를 가져옵니다.\n",
    "    popular_movies_spark_filtered = movie_stats_df_spark.filter(col(\"num_ratings\") >= min_ratings_threshold) \\\n",
    "                                                          .orderBy(desc(\"avg_rating\"), desc(\"num_ratings\")) \\\n",
    "                                                          .join(movies_df_spark, \"movieId\", \"left\")\n",
    "    popular_movies_df = popular_movies_spark_filtered.toPandas() # Pandas DataFrame으로 변환\n",
    "\n",
    "    # --- 2. 리뷰 많고 평점 높은 영화를 지정된 개수만큼 무조건 포함 ---\n",
    "    popular_added_count = 0 # 현재까지 추가된 인기 영화 수\n",
    "    for _, row in popular_movies_df.iterrows():\n",
    "        if row['movieId'] not in seen_movie_ids: # 이미 추천 목록에 있거나 사용자가 입력한 영화는 제외\n",
    "            # recommended_movies DataFrame에 현재 인기 영화 정보 추가\n",
    "            recommended_movies = pd.concat([recommended_movies, pd.DataFrame([row])], ignore_index=True)\n",
    "            seen_movie_ids.add(row['movieId']) # 중복 추가 방지를 위해 ID 기록\n",
    "            popular_added_count += 1\n",
    "            if popular_added_count >= num_popular_or_high_rated_fixed: # 필요한 인기 영화 개수를 채웠으면 중단\n",
    "                break\n",
    "    \n",
    "    # --- 3. 나머지 추천 개수 (총 num_recommendations_total 중 인기영화 제외) ---\n",
    "    remaining_recommendations_slots = num_recommendations_total - popular_added_count\n",
    "    \n",
    "    # 남은 슬롯이 없거나 음수가 되면 더 이상 콘텐츠 기반 추천을 할 필요 없음\n",
    "    if remaining_recommendations_slots <= 0:\n",
    "        # 최종 추천 목록에서 필요한 개수만큼 자르기 (중복 및 입력 영화 제거 후)\n",
    "        final_recommendations = recommended_movies[~recommended_movies['movieId'].isin(user_movie_ids)] \\\n",
    "                                .drop_duplicates(subset=['movieId']) \\\n",
    "                                .head(num_recommendations_total) \\\n",
    "                                .reset_index(drop=True)\n",
    "        return spark.createDataFrame(final_recommendations) # Spark DataFrame으로 변환하여 반환\n",
    "\n",
    "\n",
    "    # --- 4. 콘텐츠 기반 추천으로 나머지 채우기 ---\n",
    "    # 각 입력 영화에 대한 콘텐츠 기반 추천을 가져와 합치기\n",
    "    for movie_id in user_movie_ids:\n",
    "        # 필요한 remaining_recommendations_slots보다 더 많이 가져와서 중복 및 이미 추가된 인기영화 제거\n",
    "        # (remaining_recommendations_slots * 2)는 나중에 중복 제거 후에도 충분한 개수를 확보하기 위함\n",
    "        content_recs_for_one_movie = get_content_based_recommendations(\n",
    "            movie_id, cosine_sim, movies_df, indices, remaining_recommendations_slots * 2\n",
    "        )\n",
    "        for _, row in content_recs_for_one_movie.iterrows():\n",
    "            if row['movieId'] not in seen_movie_ids: # 이미 추천 목록에 있거나 사용자가 입력한 영화는 제외\n",
    "                # recommended_movies DataFrame에 현재 콘텐츠 기반 추천 영화 정보 추가\n",
    "                recommended_movies = pd.concat([recommended_movies, pd.DataFrame([row])], ignore_index=True)\n",
    "                seen_movie_ids.add(row['movieId']) # 중복 추가 방지를 위해 ID 기록\n",
    "                # 필요한 콘텐츠 기반 추천 개수(전체에서 인기 영화 개수 제외)를 채웠으면 중단\n",
    "                if len(recommended_movies) - popular_added_count >= remaining_recommendations_slots:\n",
    "                    break\n",
    "        # 전체 콘텐츠 기반 추천 개수를 채웠으면 더 이상 다른 입력 영화를 보지 않아도 됨\n",
    "        if len(recommended_movies) - popular_added_count >= remaining_recommendations_slots:\n",
    "            break\n",
    "\n",
    "    # --- 5. 여전히 추천 개수가 부족하면 추가 인기/고평점 영화로 채우기 ---\n",
    "    # (총 추천 개수 - 현재까지 추천된 영화 개수) 만큼 추가 인기 영화가 필요할 경우\n",
    "    if len(recommended_movies) < num_recommendations_total:\n",
    "        additional_popular_needed = num_recommendations_total - len(recommended_movies)\n",
    "        added_count = 0\n",
    "        for _, row in popular_movies_df.iterrows():\n",
    "            if row['movieId'] not in seen_movie_ids: # 이미 추천 목록에 있거나 사용자가 입력한 영화는 제외\n",
    "                recommended_movies = pd.concat([recommended_movies, pd.DataFrame([row])], ignore_index=True)\n",
    "                seen_movie_ids.add(row['movieId'])\n",
    "                added_count += 1\n",
    "                if added_count >= additional_popular_needed: # 필요한 추가 인기 영화 개수를 채웠으면 중단\n",
    "                    break\n",
    "\n",
    "    # 최종 추천 목록에서 필요한 개수만큼 자르기 (중복 및 입력 영화 제거 후)\n",
    "    # 1. 사용자가 이미 본(입력한) 영화는 추천 목록에서 제외합니다.\n",
    "    # 2. movieId를 기준으로 중복을 제거합니다.\n",
    "    # 3. head()를 사용하여 최종적으로 num_recommendations_total 개수만큼의 영화만 선택합니다.\n",
    "    # 4. reset_index(drop=True)로 인덱스를 재설정합니다.\n",
    "    final_recommendations = recommended_movies[~recommended_movies['movieId'].isin(user_movie_ids)] \\\n",
    "                            .drop_duplicates(subset=['movieId']) \\\n",
    "                            .head(num_recommendations_total) \\\n",
    "                            .reset_index(drop=True)\n",
    "\n",
    "    # Spark DataFrame으로 변환하여 반환 (Databricks display 함수 호환성을 위해)\n",
    "    return spark.createDataFrame(final_recommendations)\n",
    "\n",
    "\n",
    "# 5. 모델 테스트 (사용자 입력)\n",
    "\n",
    "# 사용자에게 영화 이름 또는 ID 입력 요청\n",
    "num_recommendations_output = 8 # 최종 추천할 영화 개수 설정\n",
    "num_guaranteed_popular = 2 # 추천 목록에 포함할 인기 영화 개수 조절 (총 추천 개수 내에서)\n",
    "\n",
    "while True: # 유효한 사용자 입력이 들어올 때까지 반복\n",
    "    user_input_str = input(\"추천받고 싶은 영화 이름 또는 ID를 쉼표로 구분하여 3~5개 입력하세요 (예: Toy Story, Jumanji, Braveheart 또는 1,2,13): \")\n",
    "    \n",
    "    is_id_input = True # 입력이 ID인지 이름인지 판단하는 플래그\n",
    "    processed_inputs = [] # 파싱된 입력을 저장할 리스트\n",
    "    for item in user_input_str.split(','): # 쉼표로 분리하고 각 항목 공백 제거\n",
    "        stripped_item = item.strip()\n",
    "        try:\n",
    "            processed_inputs.append(int(stripped_item)) # 숫자로 변환 시도 (ID인 경우)\n",
    "        except ValueError:\n",
    "            is_id_input = False # 숫자로 변환 실패 시 이름으로 간주\n",
    "            processed_inputs.append(stripped_item) # 이름 그대로 추가\n",
    "\n",
    "    if not (3 <= len(processed_inputs) <= 5): # 입력 개수 검증 (3개~5개)\n",
    "        print(\"영화는 3개에서 5개 사이로 입력해야 합니다. 다시 입력해주세요.\")\n",
    "        continue # 다시 입력 요청\n",
    "\n",
    "    input_movie_ids = [] # 실제 추천 시스템에 사용할 영화 ID 리스트\n",
    "    input_movie_names_display = [] # 사용자에게 보여줄 영화 이름 리스트\n",
    "\n",
    "    if is_id_input: # 입력이 영화 ID인 경우\n",
    "        input_movie_ids = processed_inputs\n",
    "        # Spark DataFrame에서 입력된 ID에 해당하는 영화 정보(ID, 제목)를 조회\n",
    "        found_movie_info = movies_df_spark.filter(col(\"movieId\").isin(input_movie_ids)).select(\"movieId\", \"title\").collect()\n",
    "        found_ids_set = {row.movieId for row in found_movie_info} # 찾은 영화 ID 집합\n",
    "        \n",
    "        if len(found_ids_set) != len(input_movie_ids): # 입력한 ID 중 찾을 수 없는 ID가 있는 경우\n",
    "            missing_ids = set(input_movie_ids) - found_ids_set\n",
    "            print(f\"오류: 다음 영화 ID를 찾을 수 없습니다: {list(missing_ids)}. 다시 입력해주세요.\")\n",
    "            continue # 다시 입력 요청\n",
    "        \n",
    "        # 찾은 영화 ID를 제목과 매핑하여 사용자에게 보여줄 이름 리스트 생성\n",
    "        movie_id_to_title = {row.movieId: row.title for row in found_movie_info}\n",
    "        input_movie_names_display = [movie_id_to_title[mid] for mid in input_movie_ids]\n",
    "        print(f\"\\n입력된 영화 ID: {input_movie_ids}\")\n",
    "\n",
    "    else: # 입력이 영화 이름인 경우\n",
    "        input_movie_names = processed_inputs\n",
    "        # Pandas DataFrame 기반의 get_movie_ids_from_names 함수 사용 (이름을 ID로 변환)\n",
    "        input_movie_ids, not_found_names = get_movie_ids_from_names(input_movie_names)\n",
    "        \n",
    "        if not_found_names: # 찾을 수 없는 영화 이름이 있는 경우\n",
    "            print(f\"다음 영화를 찾을 수 없거나 모호하여 추천을 진행할 수 없습니다: {', '.join(not_found_names)}\")\n",
    "            continue # 다시 입력 요청\n",
    "        elif len(input_movie_ids) != len(input_movie_names): # 찾았으나 개수가 다르면 문제 (일부만 찾은 경우)\n",
    "            print(\"입력된 모든 영화 이름을 영화 ID로 변환하지 못했습니다. 다시 시도해주세요.\")\n",
    "            continue # 다시 입력 요청\n",
    "        \n",
    "        input_movie_names_display = input_movie_names # 사용자에게 보여줄 이름은 입력 그대로 사용\n",
    "\n",
    "    break # 유효한 입력이 들어왔으므로 루프 종료\n",
    "\n",
    "print(f\"\\n입력된 영화: {input_movie_names_display} (ID: {input_movie_ids})를 기반으로 영화를 추천합니다:\")\n",
    "# recommend_movies_by_input 함수는 Spark DataFrame을 반환\n",
    "# num_guaranteed_popular 변수를 사용하여 최종 추천 목록에 포함될 인기 영화의 개수를 조절\n",
    "recommended_df = recommend_movies_by_input(input_movie_ids, num_recommendations_output, num_guaranteed_popular)\n",
    "# Databricks의 display 함수를 사용하여 결과를 테이블 형태로 시각화하여 출력\n",
    "# 'title'과 'genres' 컬럼만 선택하여 보여줍니다.\n",
    "display(recommended_df.select('title', 'genres'))\n",
    "\n",
    "\n",
    "# 6. 모델 성능 평가 및 시각화\n",
    "\n",
    "# 평가 지표 계산 함수 (간단한 추천 시스템의 Precision, Recall 계산)\n",
    "def evaluate_recommender(model_func, movies_df_eval, ratings_df_eval, indices_eval, cosine_sim_matrix_eval,\n",
    "                         test_ratings_df, num_recommendations_total=10, num_popular_fixed=1):\n",
    "    \"\"\"\n",
    "    추천 시스템의 평균 Precision, Recall, F1-Score를 계산합니다.\n",
    "    모든 사용자에 대해 평가하기는 어려우므로, 테스트 데이터셋에서 일부 사용자를 샘플링하여 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        model_func (function): 영화 추천을 수행하는 함수 (여기서는 recommend_movies_by_input).\n",
    "        movies_df_eval (pd.DataFrame): 영화 정보 DataFrame.\n",
    "        ratings_df_eval (pd.DataFrame): 전체 평점 정보 DataFrame.\n",
    "        indices_eval (pd.Series): 영화 제목과 인덱스 매핑 Series.\n",
    "        cosine_sim_matrix_eval (np.array): 코사인 유사도 행렬.\n",
    "        test_ratings_df (pd.DataFrame): 테스트용 평점 DataFrame.\n",
    "        num_recommendations_total (int): 모델이 추천할 총 영화 개수.\n",
    "        num_popular_fixed (int): 모델이 고정적으로 포함할 인기 영화 개수.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (평균 Precision, 평균 Recall, 평균 F1-Score, 평가된 사용자 수)\n",
    "    \"\"\"\n",
    "    total_precision = 0 # 전체 Precision 합계\n",
    "    total_recall = 0    # 전체 Recall 합계\n",
    "    total_f1 = 0        # 전체 F1-Score 합계\n",
    "    num_users_evaluated = 0 # 평가된 사용자 수\n",
    "\n",
    "    # 테스트 데이터셋에서 임의의 사용자 샘플링\n",
    "    # 전체 사용자 중 최대 50명 또는 고유 사용자 수 중 더 작은 값을 샘플링합니다.\n",
    "    sample_users = test_ratings_df['userId'].sample(min(50, test_ratings_df['userId'].nunique()), random_state=42).unique()\n",
    "\n",
    "    for user_id in sample_users:\n",
    "        # 해당 사용자의 훈련 데이터에서 가장 높은 평점을 준 영화들을 '입력 영화'로 가정\n",
    "        # 사용자가 훈련 세트에서 평점을 매긴 영화들을 평점 내림차순으로 정렬합니다.\n",
    "        user_train_movies = train_ratings[train_ratings['userId'] == user_id].sort_values(by='rating', ascending=False)\n",
    "        \n",
    "        # 훈련 데이터에서 최소 3개 이상의 영화를 본 사용자만 고려\n",
    "        if len(user_train_movies) < 3:\n",
    "            continue # 영화 수가 적으면 평가에서 제외\n",
    "            \n",
    "        # 가장 높은 평점을 준 상위 3개 영화의 ID를 시드(seed) 영화로 사용\n",
    "        # 이 영화들을 사용자가 \"좋아하는 영화\"로 간주하고 추천을 시작합니다.\n",
    "        seed_movie_ids = user_train_movies.head(3)['movieId'].tolist()\n",
    "\n",
    "        if not seed_movie_ids: # 시드 영화 ID가 없으면 건너뜀\n",
    "            continue\n",
    "\n",
    "        # 추천 받기\n",
    "        # model_func (recommend_movies_by_input) 함수를 호출하여 추천을 받습니다.\n",
    "        # 이 함수는 Spark DataFrame을 반환하므로 .toPandas()로 변환하여 처리합니다.\n",
    "        recommended_movies_df_spark = model_func(\n",
    "            seed_movie_ids, num_recommendations_total, num_popular_or_high_rated_fixed=num_popular_fixed\n",
    "        )\n",
    "        recommended_movies_df = recommended_movies_df_spark.toPandas()\n",
    "        \n",
    "        if recommended_movies_df.empty: # 추천된 영화가 없으면 건너뜀\n",
    "            continue\n",
    "\n",
    "        # 추천된 영화 ID 목록 (집합 형태로 변환하여 빠른 조회 가능)\n",
    "        recommended_movie_ids = set(recommended_movies_df['movieId'].tolist())\n",
    "\n",
    "        # 해당 사용자가 테스트 데이터에서 실제로 높은 평점을 준 영화 목록 (예: 4점 이상)\n",
    "        # 이 영화들은 사용자가 \"실제로 관련 있다고 판단한\" 영화들입니다.\n",
    "        actual_relevant_movies_df = test_ratings_df[(test_ratings_df['userId'] == user_id) & (test_ratings_df['rating'] >= 4)]\n",
    "        actual_relevant_movie_ids = set(actual_relevant_movies_df['movieId'].tolist())\n",
    "\n",
    "        # 교집합 (추천된 영화 중 실제 관련성 있는 영화 = True Positives)\n",
    "        true_positives = len(recommended_movie_ids.intersection(actual_relevant_movie_ids))\n",
    "\n",
    "        # Precision: 추천된 영화 중 실제로 관련성 있는 영화의 비율\n",
    "        # (True Positives) / (True Positives + False Positives)\n",
    "        precision = true_positives / len(recommended_movie_ids) if len(recommended_movie_ids) > 0 else 0\n",
    "\n",
    "        # Recall: 실제 관련성 있는 영화 중 추천된 영화의 비율\n",
    "        # (True Positives) / (True Positives + False Negatives)\n",
    "        recall = true_positives / len(actual_relevant_movie_ids) if len(actual_relevant_movie_ids) > 0 else 0\n",
    "\n",
    "        # F1-score: Precision과 Recall의 조화 평균 (두 지표의 균형을 나타냄)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        total_precision += precision # 각 사용자의 Precision을 합산\n",
    "        total_recall += recall       # 각 사용자의 Recall을 합산\n",
    "        total_f1 += f1               # 각 사용자의 F1-Score를 합산\n",
    "        num_users_evaluated += 1     # 평가된 사용자 수 증가\n",
    "\n",
    "    if num_users_evaluated == 0:\n",
    "        return 0, 0, 0, 0 # 평가된 사용자가 없으면 0 반환\n",
    "\n",
    "    # 평가된 사용자 수로 나누어 평균값 계산\n",
    "    avg_precision = total_precision / num_users_evaluated\n",
    "    avg_recall = total_recall / num_users_evaluated\n",
    "    avg_f1 = total_f1 / num_users_evaluated\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1, num_users_evaluated\n",
    "\n",
    "# 평가를 위한 데이터 분할 (사용자-영화 상호작용 데이터)\n",
    "# ratings_df를 훈련(80%)과 테스트(20%) 세트로 분할합니다. random_state는 재현 가능성을 보장합니다.\n",
    "train_ratings, test_ratings = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 성능 평가를 실행하는 함수\n",
    "def model_performance_evaluation():\n",
    "    print(\"\\n모델 성능 평가를 시작합니다...\")\n",
    "    # evaluate_recommender 호출 시 num_popular_fixed 변수를 전달하여 인기 영화 개수 조절\n",
    "    # 여기서는 사용자 입력 테스트에서 사용된 num_guaranteed_popular 값을 사용합니다.\n",
    "    avg_precision, avg_recall, avg_f1, num_evaluated_users = evaluate_recommender(\n",
    "        recommend_movies_by_input, movies_df, ratings_df, indices, cosine_sim, test_ratings,\n",
    "        num_recommendations_total=num_recommendations_output, # 추천할 총 영화 개수\n",
    "        num_popular_fixed=num_guaranteed_popular # 포함될 인기 영화 개수\n",
    "    )\n",
    "\n",
    "    print(f\"\\n평가된 사용자 수: {num_evaluated_users}\")\n",
    "    print(f\"평균 Precision: {avg_precision:.4f}\") # 소수점 4자리까지 출력\n",
    "    print(f\"평균 Recall: {avg_recall:.4f}\")\n",
    "    print(f\"평균 F1-Score: {avg_f1:.4f}\")\n",
    "\n",
    "    # 성능 시각화\n",
    "    metrics = ['Precision', 'Recall', 'F1-Score'] # 지표 이름 리스트\n",
    "    values = [avg_precision, avg_recall, avg_f1] # 계산된 평균값 리스트\n",
    "\n",
    "    plt.figure(figsize=(8, 6)) # 그래프 크기 설정\n",
    "    sns.barplot(x=metrics, y=values, palette='viridis') # 막대 그래프 생성 (색상 팔레트 'viridis')\n",
    "    plt.title('Recommendation System Performance Metrics') # 그래프 제목\n",
    "    plt.ylabel('Score') # Y축 레이블\n",
    "    plt.ylim(0, 1) # Y축 범위 (0에서 1까지)\n",
    "    # 각 막대 위에 정확한 점수 값 표시\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', va='bottom', fontsize=10) # 텍스트 위치 및 포맷 설정\n",
    "    plt.show() # 그래프 출력\n",
    "\n",
    "# 모델 성능 평가 함수 호출 (현재 주석 처리됨)\n",
    "model_performance_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d72e6ac-f426-4ceb-bd6b-2f4317b4c5fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Microsoft Azure Databricks Notebook.\n",
    "# Content-Based + 인기 영화 추천 시스템 (Hybrid)\n",
    "\n",
    "# 1. 라이브러리 임포트\n",
    "import pandas as pd # 데이터 처리 및 조작을 위한 필수 라이브러리\n",
    "import numpy as np # 수치 계산을 위한 라이브러리 (pandas와 함께 사용)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 텍스트 데이터를 TF-IDF 특징 벡터로 변환\n",
    "from sklearn.metrics.pairwise import linear_kernel # 코사인 유사도(선형 커널)를 효율적으로 계산\n",
    "# from sklearn.model_selection import train_test_split # 데이터셋을 훈련 세트와 테스트 세트로 분할 (Spark DataFrame 사용으로 변경)\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score # 추천 시스템 성능 평가 지표 (정밀도, 재현율, F1-점수) (직접 계산으로 변경)\n",
    "import matplotlib.pyplot as plt # 데이터 시각화를 위한 라이브러리\n",
    "import seaborn as sns # matplotlib 기반의 통계 데이터 시각화 라이브러리\n",
    "from pyspark.sql import SparkSession # Spark 애플리케이션의 진입점 (Spark DataFrame 사용에 필수)\n",
    "from pyspark.sql.functions import col, lit, count, avg, desc, udf # Spark DataFrame 컬럼 조작 함수 및 사용자 정의 함수(UDF)\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, StructType, StructField # Spark DataFrame 스키마 정의를 위한 데이터 타입\n",
    "\n",
    "# Spark 세션 초기화 (Databricks에서는 자동으로 초기화되지만 명시적으로 정의 가능)\n",
    "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
    "\n",
    "# 2. 데이터 로드 (Unity Catalog 테이블에서 불러오도록 변경)\n",
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"`final`\"\n",
    "path = f\"{catalog}.{schema}\"\n",
    "\n",
    "try:\n",
    "    # Unity Catalog에서 train, validation, test 테이블을 Spark DataFrame으로 직접 읽어옵니다.\n",
    "    train_df_spark = spark.read.table(f\"{path}.train_df\")\n",
    "    validation_df_spark = spark.read.table(f\"{path}.validation_df\")\n",
    "    test_df_spark = spark.read.table(f\"{path}.test_df\")\n",
    "\n",
    "    # movies_df_spark와 ratings_df_spark는 통합된 데이터에서 추출\n",
    "    # movies_df_spark는 train_df에서 고유한 movieId, title, genres를 추출\n",
    "    movies_df_spark = train_df_spark.select(\"movieId\", \"title\", \"genres\").distinct()\n",
    "    # ratings_df_spark는 train_df의 userId, movieId, rating, timestamp를 사용\n",
    "    ratings_df_spark = train_df_spark.select(\"userId\", \"movieId\", \"rating\", \"timestamp\") # 전체 평점 데이터 (train_df 기준)\n",
    "\n",
    "    print(\"데이터를 Unity Catalog 테이블에서 성공적으로 불러왔습니다.\")\n",
    "    print(f\"Train DataFrame 스키마: {train_df_spark.printSchema()}\")\n",
    "    print(f\"Validation DataFrame 스키마: {validation_df_spark.printSchema()}\")\n",
    "    print(f\"Test DataFrame 스키마: {test_df_spark.printSchema()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unity Catalog 테이블 로드 중 오류 발생: {e}\")\n",
    "    print(\"기존 경로 변수 방식으로 시도합니다. (데이터 경로를 다시 확인해주세요)\")\n",
    "    movies_path = \"/databricks-datasets/movielens/small/movies.csv\"\n",
    "    ratings_path = \"/databricks-datasets/movielens/small/ratings.csv\"\n",
    "    movies_df_spark = spark.read.csv(movies_path, header=True, inferSchema=True)\n",
    "    ratings_df_spark = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
    "    # 기존 movielens-small 데이터셋을 사용하는 경우 train/test 분할은 다시 진행해야 함.\n",
    "    # 여기서는 Unity Catalog의 train/test/validation 분할된 데이터를 우선적으로 사용합니다.\n",
    "    print(\"WARNING: Fallback to /databricks-datasets. Evaluation may not work as expected without pre-split data.\")\n",
    "\n",
    "# Pandas DataFrame으로 변환 (콘텐츠 기반 추천을 위해 TF-IDF를 사용하기 위함)\n",
    "movies_df = movies_df_spark.toPandas()\n",
    "ratings_df = ratings_df_spark.toPandas() # train_df_spark의 rating/timestamp 데이터 사용\n",
    "\n",
    "# 추가: 평가를 위한 test_ratings_df (Pandas DataFrame) 생성\n",
    "test_ratings_df = test_df_spark.toPandas()\n",
    "\n",
    "# 데이터 확인 (주석 처리됨)\n",
    "# print(\"Movies DataFrame head:\")\n",
    "# print(movies_df.head())\n",
    "# print(\"\\nRatings DataFrame head:\")\n",
    "# print(ratings_df.head())\n",
    "# print(\"\\nTest Ratings DataFrame head:\")\n",
    "# print(test_ratings_df.head())\n",
    "\n",
    "# 3. 데이터 전처리 및 콘텐츠 기반 추천 시스템 구축\n",
    "\n",
    "# 장르 데이터 클리닝 및 TF-IDF 벡터화\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df['genres'])\n",
    "\n",
    "print(f\"\\nTF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# 코사인 유사도 계산 (콘텐츠 기반 유사도)\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 영화 제목과 인덱스를 매핑하는 시리즈 생성\n",
    "indices = pd.Series(movies_df.index, index=movies_df['title']).drop_duplicates()\n",
    "\n",
    "# 영화 ID로 제목을 찾는 헬퍼 함수 (Pandas DataFrame 사용)\n",
    "def get_title_from_id(movie_id):\n",
    "    \"\"\"\n",
    "    주어진 영화 ID에 해당하는 영화 제목을 movies_df에서 찾아 반환합니다.\n",
    "    \"\"\"\n",
    "    if movie_id in movies_df['movieId'].values:\n",
    "        return movies_df[movies_df['movieId'] == movie_id]['title'].iloc[0]\n",
    "    return None\n",
    "\n",
    "# 영화 이름으로 ID를 찾는 헬퍼 함수 (Pandas DataFrame 사용)\n",
    "def get_movie_ids_from_names(movie_names):\n",
    "    \"\"\"\n",
    "    주어진 영화 이름 리스트에 해당하는 영화 ID들을 찾아 반환합니다.\n",
    "    찾을 수 없는 영화 이름도 별도로 반환합니다.\n",
    "    \"\"\"\n",
    "    found_ids = []\n",
    "    not_found_names = []\n",
    "    for name in movie_names:\n",
    "        match = movies_df[movies_df['title'].str.lower() == name.lower()]\n",
    "        if not match.empty:\n",
    "            found_ids.append(match['movieId'].iloc[0])\n",
    "        else:\n",
    "            not_found_names.append(name)\n",
    "    return found_ids, not_found_names\n",
    "\n",
    "# 4. 추천 함수 정의\n",
    "\n",
    "def get_content_based_recommendations(movie_id, cosine_sim_matrix, movies_df_local, indices_local, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    콘텐츠(장르) 기반으로 유사한 영화를 추천합니다. (movie_id 기반)\n",
    "\n",
    "    Args:\n",
    "        movie_id (int): 기준이 될 영화의 ID.\n",
    "        cosine_sim_matrix (np.array): 영화 간 코사인 유사도 행렬.\n",
    "        movies_df_local (pd.DataFrame): 영화 정보가 담긴 Pandas DataFrame.\n",
    "        indices_local (pd.Series): 영화 제목과 인덱스를 매핑하는 Series.\n",
    "        num_recommendations (int): 추천할 영화의 개수.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 추천된 영화들의 정보 (Pandas DataFrame).\n",
    "    \"\"\"\n",
    "    movie_title = get_title_from_id(movie_id)\n",
    "    if not movie_title or movie_title not in indices_local:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    idx = indices_local[movie_title]\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies_df_local.iloc[movie_indices]\n",
    "\n",
    "\n",
    "def recommend_movies_by_input(user_movie_ids, num_recommendations_total, num_popular_or_high_rated_fixed):\n",
    "    \"\"\"\n",
    "    사용자가 입력한 영화 ID를 기반으로 콘텐츠 기반 추천 + 인기/고평점 영화를 섞어서 추천합니다.\n",
    "    num_popular_or_high_rated_fixed 만큼 리뷰 많고 평점 높은 영화를 무조건 포함합니다.\n",
    "\n",
    "    Args:\n",
    "        user_movie_ids (list): 사용자가 입력한 영화 ID 리스트.\n",
    "        num_recommendations_total (int): 최종적으로 추천할 총 영화 개수.\n",
    "        num_popular_or_high_rated_fixed (int): 추천 목록에 무조건 포함할 인기/고평점 영화의 개수.\n",
    "\n",
    "    Returns:\n",
    "        pyspark.sql.DataFrame: 최종 추천된 영화들의 Spark DataFrame (movieId만 포함).\n",
    "    \"\"\"\n",
    "    recommended_movies_df_pandas = pd.DataFrame(columns=['movieId']) # 추천된 영화 ID들을 저장할 Pandas DataFrame\n",
    "    seen_movie_ids = set(user_movie_ids) # 사용자가 이미 입력한 영화 ID를 저장하여 추천 목록에서 제외\n",
    "\n",
    "    # --- 1. 리뷰 많고 평점 높은 영화 목록 미리 계산 (Spark DataFrame 사용) ---\n",
    "    # ratings_df_spark를 사용하여 영화별 리뷰 수(num_ratings)와 평균 평점(avg_rating)을 집계합니다.\n",
    "    movie_stats_df_spark = ratings_df_spark.groupBy(\"movieId\").agg(\n",
    "        count(col(\"rating\")).alias(\"num_ratings\"),\n",
    "        avg(col(\"rating\")).alias(\"avg_rating\")\n",
    "    )\n",
    "\n",
    "    min_ratings_threshold = 50 # 최소 리뷰 수 임계값\n",
    "    popular_movies_spark_filtered = movie_stats_df_spark.filter(col(\"num_ratings\") >= min_ratings_threshold) \\\n",
    "                                                         .orderBy(desc(\"avg_rating\"), desc(\"num_ratings\"))\n",
    "    popular_movies_df_pandas = popular_movies_spark_filtered.toPandas() # Pandas DataFrame으로 변환\n",
    "\n",
    "    # --- 2. 리뷰 많고 평점 높은 영화를 지정된 개수만큼 무조건 포함 ---\n",
    "    popular_added_count = 0\n",
    "    for _, row in popular_movies_df_pandas.iterrows():\n",
    "        if row['movieId'] not in seen_movie_ids:\n",
    "            recommended_movies_df_pandas = pd.concat([recommended_movies_df_pandas, pd.DataFrame([{'movieId': row['movieId']}])], ignore_index=True)\n",
    "            seen_movie_ids.add(row['movieId'])\n",
    "            popular_added_count += 1\n",
    "            if popular_added_count >= num_popular_or_high_rated_fixed:\n",
    "                break\n",
    "    \n",
    "    # --- 3. 나머지 추천 개수 (총 num_recommendations_total 중 인기영화 제외) ---\n",
    "    remaining_recommendations_slots = num_recommendations_total - popular_added_count\n",
    "    \n",
    "    # 남은 슬롯이 없거나 음수가 되면 더 이상 콘텐츠 기반 추천을 할 필요 없음\n",
    "    if remaining_recommendations_slots <= 0:\n",
    "        final_recommendations = recommended_movies_df_pandas[~recommended_movies_df_pandas['movieId'].isin(user_movie_ids)] \\\n",
    "                                 .drop_duplicates(subset=['movieId']) \\\n",
    "                                 .head(num_recommendations_total) \\\n",
    "                                 .reset_index(drop=True)\n",
    "        # 결과 스키마 정의 (movieId만 포함)\n",
    "        schema = StructType([StructField(\"movieId\", IntegerType(), True)])\n",
    "        return spark.createDataFrame(final_recommendations, schema=schema)\n",
    "\n",
    "\n",
    "    # --- 4. 콘텐츠 기반 추천으로 나머지 채우기 ---\n",
    "    for movie_id in user_movie_ids:\n",
    "        content_recs_for_one_movie = get_content_based_recommendations(\n",
    "            movie_id, cosine_sim, movies_df, indices, remaining_recommendations_slots * 2\n",
    "        )\n",
    "        for _, row in content_recs_for_one_movie.iterrows():\n",
    "            if row['movieId'] not in seen_movie_ids:\n",
    "                recommended_movies_df_pandas = pd.concat([recommended_movies_df_pandas, pd.DataFrame([{'movieId': row['movieId']}])], ignore_index=True)\n",
    "                seen_movie_ids.add(row['movieId'])\n",
    "                if len(recommended_movies_df_pandas) - popular_added_count >= remaining_recommendations_slots:\n",
    "                    break\n",
    "        if len(recommended_movies_df_pandas) - popular_added_count >= remaining_recommendations_slots:\n",
    "            break\n",
    "\n",
    "    # --- 5. 여전히 추천 개수가 부족하면 추가 인기/고평점 영화로 채우기 ---\n",
    "    if len(recommended_movies_df_pandas) < num_recommendations_total:\n",
    "        additional_popular_needed = num_recommendations_total - len(recommended_movies_df_pandas)\n",
    "        added_count = 0\n",
    "        for _, row in popular_movies_df_pandas.iterrows():\n",
    "            if row['movieId'] not in seen_movie_ids:\n",
    "                recommended_movies_df_pandas = pd.concat([recommended_movies_df_pandas, pd.DataFrame([{'movieId': row['movieId']}])], ignore_index=True)\n",
    "                seen_movie_ids.add(row['movieId'])\n",
    "                added_count += 1\n",
    "                if added_count >= additional_popular_needed:\n",
    "                    break\n",
    "\n",
    "    # 최종 추천 목록에서 필요한 개수만큼 자르기 (중복 및 입력 영화 제거 후)\n",
    "    final_recommendations = recommended_movies_df_pandas[~recommended_movies_df_pandas['movieId'].isin(user_movie_ids)] \\\n",
    "                             .drop_duplicates(subset=['movieId']) \\\n",
    "                             .head(num_recommendations_total) \\\n",
    "                             .reset_index(drop=True)\n",
    "    \n",
    "    # 결과 스키마 정의 (movieId만 포함)\n",
    "    schema = StructType([StructField(\"movieId\", IntegerType(), True)])\n",
    "    return spark.createDataFrame(final_recommendations, schema=schema)\n",
    "\n",
    "# 5. 모델 테스트 (사용자 입력) - 주석 처리\n",
    "# num_recommendations_output = 8\n",
    "# num_guaranteed_popular = 2\n",
    "\n",
    "# while True:\n",
    "#     user_input_str = input(\"추천받고 싶은 영화 이름 또는 ID를 쉼표로 구분하여 3~5개 입력하세요 (예: Toy Story, Jumanji, Braveheart 또는 1,2,13): \")\n",
    "    \n",
    "#     is_id_input = True\n",
    "#     processed_inputs = []\n",
    "#     for item in user_input_str.split(','):\n",
    "#         stripped_item = item.strip()\n",
    "#         try:\n",
    "#             processed_inputs.append(int(stripped_item))\n",
    "#         except ValueError:\n",
    "#             is_id_input = False\n",
    "#             processed_inputs.append(stripped_item)\n",
    "\n",
    "#     if not (3 <= len(processed_inputs) <= 5):\n",
    "#         print(\"영화는 3개에서 5개 사이로 입력해야 합니다. 다시 입력해주세요.\")\n",
    "#         continue\n",
    "\n",
    "#     input_movie_ids = []\n",
    "#     input_movie_names_display = []\n",
    "\n",
    "#     if is_id_input:\n",
    "#         input_movie_ids = processed_inputs\n",
    "#         found_movie_info = movies_df_spark.filter(col(\"movieId\").isin(input_movie_ids)).select(\"movieId\", \"title\").collect()\n",
    "#         found_ids_set = {row.movieId for row in found_movie_info}\n",
    "        \n",
    "#         if len(found_ids_set) != len(input_movie_ids):\n",
    "#             missing_ids = set(input_movie_ids) - found_ids_set\n",
    "#             print(f\"오류: 다음 영화 ID를 찾을 수 없습니다: {list(missing_ids)}. 다시 입력해주세요.\")\n",
    "#             continue\n",
    "        \n",
    "#         movie_id_to_title = {row.movieId: row.title for row in found_movie_info}\n",
    "#         input_movie_names_display = [movie_id_to_title[mid] for mid in input_movie_ids]\n",
    "#         print(f\"\\n입력된 영화 ID: {input_movie_ids}\")\n",
    "\n",
    "#     else:\n",
    "#         input_movie_names = processed_inputs\n",
    "#         input_movie_ids, not_found_names = get_movie_ids_from_names(input_movie_names)\n",
    "        \n",
    "#         if not_found_names:\n",
    "#             print(f\"다음 영화를 찾을 수 없거나 모호하여 추천을 진행할 수 없습니다: {', '.join(not_found_names)}\")\n",
    "#             continue\n",
    "#         elif len(input_movie_ids) != len(input_movie_names):\n",
    "#             print(\"입력된 모든 영화 이름을 영화 ID로 변환하지 못했습니다. 다시 시도해주세요.\")\n",
    "#             continue\n",
    "        \n",
    "#         input_movie_names_display = input_movie_names\n",
    "\n",
    "#     break\n",
    "\n",
    "# print(f\"\\n입력된 영화: {input_movie_names_display} (ID: {input_movie_ids})를 기반으로 영화를 추천합니다:\")\n",
    "# recommended_df = recommend_movies_by_input(input_movie_ids, num_recommendations_output, num_guaranteed_popular)\n",
    "# # recommended_df는 movieId만 포함하므로, display 함수로 보여주기 위해 다시 join 필요\n",
    "# final_display_df = recommended_df.join(movies_df_spark, \"movieId\", \"left\").select('title', 'genres')\n",
    "# display(final_display_df)\n",
    "\n",
    "\n",
    "# 6. 모델 성능 평가 및 시각화\n",
    "\n",
    "# NDCG (Normalized Discounted Cumulative Gain) 계산 함수\n",
    "def calculate_ndcg_at_k(recommended_items, relevant_items, k):\n",
    "    \"\"\"\n",
    "    NDCG@k를 계산합니다.\n",
    "    Args:\n",
    "        recommended_items (list): 추천된 아이템 ID 리스트.\n",
    "        relevant_items (set): 관련성 있는 아이템 ID 집합.\n",
    "        k (int): 평가할 상위 K개 아이템.\n",
    "    Returns:\n",
    "        float: NDCG@k 값.\n",
    "    \"\"\"\n",
    "    if not relevant_items:\n",
    "        return 0.0\n",
    "\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "\n",
    "    for i in range(k):\n",
    "        if i < len(recommended_items):\n",
    "            item = recommended_items[i]\n",
    "            if item in relevant_items:\n",
    "                dcg += 1.0 / np.log2(i + 2) # i+1은 0-based index이므로, log2(position + 1)\n",
    "        \n",
    "        # Ideal DCG (가장 이상적인 추천 순서)\n",
    "        if i < len(relevant_items):\n",
    "            idcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# 평가 지표 계산 함수 (Precision@k, Recall@k, NDCG@k)\n",
    "def evaluate_recommender(model_func, movies_df_eval, ratings_df_eval, indices_eval, cosine_sim_matrix_eval,\n",
    "                         test_ratings_df_eval, train_ratings_df_eval, k=10, num_popular_fixed=1):\n",
    "    \"\"\"\n",
    "    추천 시스템의 평균 Precision@k, Recall@k, NDCG@k를 계산하고,\n",
    "    각 유저별 추천 결과를 포함하는 DataFrame을 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        model_func (function): 영화 추천을 수행하는 함수 (여기서는 recommend_movies_by_input).\n",
    "        movies_df_eval (pd.DataFrame): 영화 정보 DataFrame.\n",
    "        ratings_df_eval (pd.DataFrame): 전체 평점 정보 DataFrame (훈련 데이터를 포함).\n",
    "        indices_eval (pd.Series): 영화 제목과 인덱스 매핑 Series.\n",
    "        cosine_sim_matrix_eval (np.array): 코사인 유사도 행렬.\n",
    "        test_ratings_df_eval (pd.DataFrame): 테스트용 평점 DataFrame.\n",
    "        train_ratings_df_eval (pd.DataFrame): 훈련용 평점 DataFrame.\n",
    "        k (int): 평가할 상위 K개 영화.\n",
    "        num_popular_fixed (int): 모델이 고정적으로 포함할 인기 영화 개수.\n",
    "    Returns:\n",
    "        tuple: (평균 Precision@k, 평균 Recall@k, 평균 NDCG@k, 평가된 사용자 수, 사용자별 추천 결과 DataFrame)\n",
    "    \"\"\"\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_ndcg = 0\n",
    "    num_users_evaluated = 0\n",
    "    \n",
    "    # 사용자별 추천 결과를 저장할 리스트\n",
    "    user_recommendations_data = []\n",
    "\n",
    "    # 테스트 데이터셋에서 임의의 사용자 샘플링 (최대 100명 또는 고유 사용자 수 중 더 작은 값)\n",
    "    sample_users = test_ratings_df_eval['userId'].sample(min(100, test_ratings_df_eval['userId'].nunique()), random_state=42).unique()\n",
    "\n",
    "    for user_id in sample_users:\n",
    "        # 해당 사용자의 훈련 데이터에서 가장 높은 평점을 준 영화들을 '입력 영화'로 가정\n",
    "        # (4점 이상 평점을 준 영화들 중 상위 3개)\n",
    "        user_train_movies_high_rated = train_ratings_df_eval[(train_ratings_df_eval['userId'] == user_id) & (train_ratings_df_eval['rating'] >= 4)] \\\n",
    "                                        .sort_values(by='rating', ascending=False)\n",
    "        \n",
    "        if len(user_train_movies_high_rated) < 3: # 최소 3개 이상의 높은 평점 영화가 없으면 평가 제외\n",
    "            continue\n",
    "            \n",
    "        seed_movie_ids = user_train_movies_high_rated.head(3)['movieId'].tolist()\n",
    "\n",
    "        if not seed_movie_ids:\n",
    "            continue\n",
    "\n",
    "        # 추천 받기\n",
    "        recommended_movies_df_spark = model_func(\n",
    "            seed_movie_ids, k, num_popular_or_high_rated_fixed=num_popular_fixed\n",
    "        )\n",
    "        recommended_movie_ids_list = [row.movieId for row in recommended_movies_df_spark.collect()]\n",
    "        \n",
    "        if not recommended_movie_ids_list:\n",
    "            continue\n",
    "\n",
    "        # 실제 관련성 있는 영화: 테스트 데이터에서 해당 사용자가 4점 이상 평점을 준 영화\n",
    "        actual_relevant_movies_df = test_ratings_df_eval[(test_ratings_df_eval['userId'] == user_id) & (test_ratings_df_eval['rating'] >= 4)]\n",
    "        actual_relevant_movie_ids = set(actual_relevant_movies_df['movieId'].tolist())\n",
    "\n",
    "        # 추천된 영화 ID 리스트를 k개로 자르기\n",
    "        recommended_k = recommended_movie_ids_list[:k]\n",
    "\n",
    "        # Precision@k\n",
    "        true_positives = len(set(recommended_k).intersection(actual_relevant_movie_ids))\n",
    "        precision_k = true_positives / k if k > 0 else 0\n",
    "\n",
    "        # Recall@k\n",
    "        recall_k = true_positives / len(actual_relevant_movie_ids) if len(actual_relevant_movie_ids) > 0 else 0\n",
    "\n",
    "        # NDCG@k\n",
    "        ndcg_k = calculate_ndcg_at_k(recommended_k, actual_relevant_movie_ids, k)\n",
    "\n",
    "        total_precision += precision_k\n",
    "        total_recall += recall_k\n",
    "        total_ndcg += ndcg_k\n",
    "        num_users_evaluated += 1\n",
    "\n",
    "        # 사용자별 추천 결과 저장\n",
    "        user_recommendations_data.append({\n",
    "            'userId': user_id,\n",
    "            'seed_movie_ids': seed_movie_ids,\n",
    "            'recommended_movie_ids': recommended_k,\n",
    "            'actual_relevant_movie_ids': list(actual_relevant_movie_ids), # Set to list for DataFrame\n",
    "            'precision_at_k': precision_k,\n",
    "            'recall_at_k': recall_k,\n",
    "            'ndcg_at_k': ndcg_k\n",
    "        })\n",
    "\n",
    "    user_recs_df = pd.DataFrame(user_recommendations_data)\n",
    "\n",
    "\n",
    "    if num_users_evaluated == 0:\n",
    "        return 0, 0, 0, 0, pd.DataFrame()\n",
    "\n",
    "    avg_precision = total_precision / num_users_evaluated\n",
    "    avg_recall = total_recall / num_users_evaluated\n",
    "    avg_ndcg = total_ndcg / num_users_evaluated\n",
    "\n",
    "    return avg_precision, avg_recall, avg_ndcg, num_users_evaluated, user_recs_df\n",
    "\n",
    "# 모델 성능 평가 함수 호출\n",
    "def model_performance_evaluation(k_val=10, popular_count=2):\n",
    "    print(\"\\n모델 성능 평가를 시작합니다...\")\n",
    "    # evaluate_recommender 함수에 train_ratings_df_eval를 전달 (훈련 데이터)\n",
    "    avg_precision, avg_recall, avg_ndcg, num_evaluated_users, user_recs_df = evaluate_recommender(\n",
    "        recommend_movies_by_input, movies_df, ratings_df, indices, cosine_sim, \n",
    "        test_ratings_df, ratings_df, # ratings_df는 train_df_spark.toPandas()로 생성되었으므로, 훈련 데이터 역할을 합니다.\n",
    "        k=k_val, # 평가할 K 값\n",
    "        num_popular_fixed=popular_count # 포함될 인기 영화 개수\n",
    "    )\n",
    "\n",
    "    print(f\"\\n평가된 사용자 수: {num_evaluated_users}\")\n",
    "    print(f\"평균 Precision@{k_val}: {avg_precision:.4f}\")\n",
    "    print(f\"평균 Recall@{k_val}: {avg_recall:.4f}\")\n",
    "    print(f\"평균 NDCG@{k_val}: {avg_ndcg:.4f}\")\n",
    "\n",
    "    # 성능 시각화\n",
    "    metrics = [f'Precision@{k_val}', f'Recall@{k_val}', f'NDCG@{k_val}']\n",
    "    values = [avg_precision, avg_recall, avg_ndcg]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=metrics, y=values, palette='viridis')\n",
    "    plt.title(f'Recommendation System Performance Metrics (k={k_val})')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', va='bottom', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "    # 사용자별 추천 결과 DataFrame 출력\n",
    "    print(\"\\n--- 사용자별 추천 결과 (샘플) ---\")\n",
    "    # recommended_movie_ids를 영화 제목으로 변환하여 보기 좋게 출력\n",
    "    user_recs_df['recommended_movie_titles'] = user_recs_df['recommended_movie_ids'].apply(\n",
    "        lambda ids: [get_title_from_id(mid) for mid in ids]\n",
    "    )\n",
    "    user_recs_df['seed_movie_titles'] = user_recs_df['seed_movie_ids'].apply(\n",
    "        lambda ids: [get_title_from_id(mid) for mid in ids]\n",
    "    )\n",
    "    user_recs_df['actual_relevant_movie_titles'] = user_recs_df['actual_relevant_movie_ids'].apply(\n",
    "        lambda ids: [get_title_from_id(mid) for mid in ids]\n",
    "    )\n",
    "\n",
    "    # 필요한 컬럼만 선택하여 출력\n",
    "    display(user_recs_df[['userId', 'recommended_movie_titles']])\n",
    "\n",
    "# 평가 실행 (예: k=10, 인기 영화 2개 고정)\n",
    "model_performance_evaluation(k_val=10, popular_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b1ac58f-e4b8-4a9c-ab5a-6f4643c439ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Microsoft Azure Databricks Notebook.\n",
    "# Content-Based + 인기 영화 추천 시스템 (Hybrid - Multi-Hot Encoding & Weighted Linear Combination)\n",
    "\n",
    "# 1. 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 텍스트 데이터를 TF-IDF 특징 벡터로 변환\n",
    "from sklearn.metrics.pairwise import linear_kernel # 코사인 유사도(선형 커널)를 효율적으로 계산\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, count, avg, desc, udf\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, StructType, StructField, DoubleType\n",
    "\n",
    "# Spark 세션 초기화 (Databricks에서는 자동으로 초기화되지만 명시적으로 정의 가능)\n",
    "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
    "\n",
    "# 2. 데이터 로드 (Unity Catalog 테이블에서 불러오도록 변경)\n",
    "catalog = \"1dt_team8_databricks\"\n",
    "schema = \"`final`\"\n",
    "path = f\"{catalog}.{schema}\"\n",
    "\n",
    "try:\n",
    "    # Unity Catalog에서 train, validation, test 테이블을 Spark DataFrame으로 직접 읽어옵니다.\n",
    "    train_df_spark = spark.read.table(f\"{path}.train_df\")\n",
    "    validation_df_spark = spark.read.table(f\"{path}.validation_df\")\n",
    "    test_df_spark = spark.read.table(f\"{path}.test_df\")\n",
    "\n",
    "    # movies_df_spark와 ratings_df_spark는 통합된 데이터에서 추출\n",
    "    # movies_df_spark는 train_df에서 고유한 movieId, title, genres를 추출\n",
    "    movies_df_spark = train_df_spark.select(\"movieId\", \"title\", \"genres\").distinct()\n",
    "    # ratings_df_spark는 train_df의 userId, movieId, rating, timestamp를 사용\n",
    "    ratings_df_spark = train_df_spark.select(\"userId\", \"movieId\", \"rating\", \"timestamp\") # 전체 평점 데이터 (train_df 기준)\n",
    "\n",
    "    print(\"데이터를 Unity Catalog 테이블에서 성공적으로 불러왔습니다.\")\n",
    "    print(f\"Train DataFrame 스키마: {train_df_spark.printSchema()}\")\n",
    "    print(f\"Validation DataFrame 스키마: {validation_df_spark.printSchema()}\")\n",
    "    print(f\"Test DataFrame 스키마: {test_df_spark.printSchema()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unity Catalog 테이블 로드 중 오류 발생: {e}\")\n",
    "    print(\"기존 경로 변수 방식으로 시도합니다. (데이터 경로를 다시 확인해주세요)\")\n",
    "    movies_path = \"/databricks-datasets/movielens/small/movies.csv\"\n",
    "    ratings_path = \"/databricks-datasets/movielens/small/ratings.csv\"\n",
    "    movies_df_spark = spark.read.csv(movies_path, header=True, inferSchema=True)\n",
    "    ratings_df_spark = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
    "    print(\"WARNING: Fallback to /databricks-datasets. Evaluation may not work as expected without pre-split data.\")\n",
    "\n",
    "# Pandas DataFrame으로 변환\n",
    "movies_df = movies_df_spark.toPandas()\n",
    "ratings_df = ratings_df_spark.toPandas()\n",
    "test_ratings_df = test_df_spark.toPandas()\n",
    "\n",
    "# 3. 데이터 전처리 및 콘텐츠 기반 추천 시스템 구축 (Multi-Hot Encoding 적용)\n",
    "\n",
    "# 장르 데이터 클리닝 및 멀티-핫 인코딩\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "\n",
    "# 각 영화의 장르를 '|' 기준으로 분리하고, 전체 장르 집합을 얻음\n",
    "all_genres = set()\n",
    "for genres_str in movies_df['genres']:\n",
    "    for genre in genres_str.split('|'):\n",
    "        if genre: # 빈 문자열 방지\n",
    "            all_genres.add(genre)\n",
    "\n",
    "# 각 장르를 공백으로 구분된 문자열로 변환 (TF-IDF를 위해)\n",
    "# 예: 'Action|Adventure' -> 'Action Adventure'\n",
    "movies_df['genres_processed'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')) if x else '')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df['genres_processed'])\n",
    "\n",
    "print(f\"\\nTF-IDF matrix shape (after Multi-Hot Encoding for genres): {tfidf_matrix.shape}\")\n",
    "\n",
    "# 코사인 유사도 계산 (콘텐츠 기반 유사도)\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 영화 제목과 인덱스를 매핑하는 시리즈 생성\n",
    "indices = pd.Series(movies_df.index, index=movies_df['title']).drop_duplicates()\n",
    "\n",
    "# 영화 ID로 제목을 찾는 헬퍼 함수 (Pandas DataFrame 사용)\n",
    "def get_title_from_id(movie_id):\n",
    "    \"\"\"\n",
    "    주어진 영화 ID에 해당하는 영화 제목을 movies_df에서 찾아 반환합니다.\n",
    "    \"\"\"\n",
    "    if movie_id in movies_df['movieId'].values:\n",
    "        return movies_df[movies_df['movieId'] == movie_id]['title'].iloc[0]\n",
    "    return None\n",
    "\n",
    "# 영화 이름으로 ID를 찾는 헬퍼 함수 (Pandas DataFrame 사용)\n",
    "def get_movie_ids_from_names(movie_names):\n",
    "    \"\"\"\n",
    "    주어진 영화 이름 리스트에 해당하는 영화 ID들을 찾아 반환합니다.\n",
    "    찾을 수 없는 영화 이름도 별도로 반환합니다.\n",
    "    \"\"\"\n",
    "    found_ids = []\n",
    "    not_found_names = []\n",
    "    for name in movie_names:\n",
    "        match = movies_df[movies_df['title'].str.lower() == name.lower()]\n",
    "        if not match.empty:\n",
    "            found_ids.append(match['movieId'].iloc[0])\n",
    "        else:\n",
    "            not_found_names.append(name)\n",
    "    return found_ids, not_found_names\n",
    "\n",
    "# 4. 추천 함수 정의 (가중치 기반 선형 결합 적용)\n",
    "\n",
    "def get_content_based_recommendations(movie_id, cosine_sim_matrix, movies_df_local, indices_local, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    콘텐츠(장르) 기반으로 유사한 영화를 추천합니다. (movie_id 기반)\n",
    "\n",
    "    Args:\n",
    "        movie_id (int): 기준이 될 영화의 ID.\n",
    "        cosine_sim_matrix (np.array): 영화 간 코사인 유사도 행렬.\n",
    "        movies_df_local (pd.DataFrame): 영화 정보가 담긴 Pandas DataFrame.\n",
    "        indices_local (pd.Series): 영화 제목과 인덱스를 매핑하는 Series.\n",
    "        num_recommendations (int): 추천할 영화의 개수.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 추천된 영화들의 정보 (Pandas DataFrame).\n",
    "    \"\"\"\n",
    "    movie_title = get_title_from_id(movie_id)\n",
    "    if not movie_title or movie_title not in indices_local:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    idx = indices_local[movie_title]\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sim_scores = sim_scores[1:num_recommendations + 1] # 자기 자신 제외\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies_df_local.iloc[movie_indices]\n",
    "\n",
    "\n",
    "def recommend_movies_weighted_hybrid(user_movie_ids, num_recommendations_total,\n",
    "                                      content_weight=0.7, popular_weight=0.3):\n",
    "    \"\"\"\n",
    "    사용자가 입력한 영화 ID를 기반으로 콘텐츠 기반 추천과 인기/고평점 영화 추천을\n",
    "    가중치를 주어 선형 결합하여 추천합니다.\n",
    "\n",
    "    Args:\n",
    "        user_movie_ids (list): 사용자가 입력한 영화 ID 리스트.\n",
    "        num_recommendations_total (int): 최종적으로 추천할 총 영화 개수.\n",
    "        content_weight (float): 콘텐츠 기반 추천에 부여할 가중치 (0.0 ~ 1.0).\n",
    "        popular_weight (float): 인기/고평점 추천에 부여할 가중치 (0.0 ~ 1.0).\n",
    "                                (content_weight + popular_weight는 1.0이 될 필요는 없지만, 일반적으로는 1.0으로 정규화하여 사용)\n",
    "\n",
    "    Returns:\n",
    "        pyspark.sql.DataFrame: 최종 추천된 영화들의 Spark DataFrame (movieId만 포함).\n",
    "    \"\"\"\n",
    "    if not user_movie_ids:\n",
    "        # 입력 영화가 없으면 인기/고평점 영화만 추천\n",
    "        popular_movies_spark_filtered = ratings_df_spark.groupBy(\"movieId\").agg(\n",
    "            count(col(\"rating\")).alias(\"num_ratings\"),\n",
    "            avg(col(\"rating\")).alias(\"avg_rating\")\n",
    "        ).filter(col(\"num_ratings\") >= 50) \\\n",
    "         .orderBy(desc(\"avg_rating\"), desc(\"num_ratings\"))\n",
    "\n",
    "        final_recommendations_spark = popular_movies_spark_filtered.select(\"movieId\").limit(num_recommendations_total)\n",
    "        return final_recommendations_spark\n",
    "\n",
    "\n",
    "    seen_movie_ids = set(user_movie_ids)\n",
    "\n",
    "    # --- 1. 콘텐츠 기반 추천 목록 생성 ---\n",
    "    content_based_recs_df = pd.DataFrame(columns=['movieId', 'score'])\n",
    "    for movie_id in user_movie_ids:\n",
    "        # 각 입력 영화에 대해 충분히 많은 콘텐츠 기반 추천을 가져옴\n",
    "        content_recs_for_one_movie = get_content_based_recommendations(\n",
    "            movie_id, cosine_sim, movies_df, indices, num_recommendations_total * 5 # 충분히 많이 가져옴\n",
    "        )\n",
    "        if not content_recs_for_one_movie.empty:\n",
    "            # 코사인 유사도 점수를 score로 사용 (0~1 범위)\n",
    "            current_movie_idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
    "            sim_scores_for_movie = linear_kernel(tfidf_matrix[current_movie_idx], tfidf_matrix[content_recs_for_one_movie.index]).flatten()\n",
    "\n",
    "            temp_df = pd.DataFrame({\n",
    "                'movieId': content_recs_for_one_movie['movieId'],\n",
    "                'score': sim_scores_for_movie\n",
    "            })\n",
    "            content_based_recs_df = pd.concat([content_based_recs_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # 중복 제거 및 점수 합산 (동일 영화에 대한 여러 입력 영화로부터의 추천을 합산)\n",
    "    content_based_recs_df = content_based_recs_df.groupby('movieId')['score'].sum().reset_index()\n",
    "    # 사용자가 본 영화 제외\n",
    "    content_based_recs_df = content_based_recs_df[~content_based_recs_df['movieId'].isin(seen_movie_ids)]\n",
    "    # 점수 정규화 (0~1)\n",
    "    if not content_based_recs_df.empty:\n",
    "        max_content_score = content_based_recs_df['score'].max()\n",
    "        if max_content_score > 0:\n",
    "            content_based_recs_df['score'] = content_based_recs_df['score'] / max_content_score\n",
    "    content_based_recs_df = content_based_recs_df.rename(columns={'score': 'content_score'})\n",
    "\n",
    "\n",
    "    # --- 2. 인기/고평점 영화 목록 생성 ---\n",
    "    movie_stats_df_spark = ratings_df_spark.groupBy(\"movieId\").agg(\n",
    "        count(col(\"rating\")).alias(\"num_ratings\"),\n",
    "        avg(col(\"rating\")).alias(\"avg_rating\")\n",
    "    )\n",
    "    min_ratings_threshold = 50 # 최소 리뷰 수 임계값\n",
    "    popular_movies_spark_filtered = movie_stats_df_spark.filter(col(\"num_ratings\") >= min_ratings_threshold) \\\n",
    "                                                          .orderBy(desc(\"avg_rating\"), desc(\"num_ratings\"))\n",
    "    popular_movies_df_pandas = popular_movies_spark_filtered.toPandas()\n",
    "\n",
    "    # 인기/고평점 점수 정규화 (avg_rating을 사용, 0~1)\n",
    "    if not popular_movies_df_pandas.empty:\n",
    "        max_avg_rating = popular_movies_df_pandas['avg_rating'].max()\n",
    "        if max_avg_rating > 0:\n",
    "            popular_movies_df_pandas['popular_score'] = popular_movies_df_pandas['avg_rating'] / max_avg_rating\n",
    "        else: # max_avg_rating이 0인 경우 (예외 처리)\n",
    "             popular_movies_df_pandas['popular_score'] = 0.0\n",
    "    else:\n",
    "        popular_movies_df_pandas['popular_score'] = 0.0\n",
    "\n",
    "\n",
    "    # --- 3. 두 추천 목록 결합 및 가중치 적용 ---\n",
    "    # 각 영화에 대한 콘텐츠 점수와 인기 점수를 합칠 DataFrame 준비\n",
    "    # 먼저, 모든 영화 ID를 포함하는 기준 DataFrame 생성\n",
    "    all_movie_ids = movies_df_spark.select(\"movieId\").distinct().toPandas()\n",
    "    hybrid_recs_df = all_movie_ids.copy()\n",
    "    hybrid_recs_df['content_score'] = 0.0\n",
    "    hybrid_recs_df['popular_score'] = 0.0\n",
    "\n",
    "    # 콘텐츠 점수 병합\n",
    "    hybrid_recs_df = pd.merge(hybrid_recs_df, content_based_recs_df, on='movieId', how='left', suffixes=('_old', ''))\n",
    "    hybrid_recs_df['content_score'] = hybrid_recs_df['content_score'].fillna(0) # merge 시 NaN 처리\n",
    "    # popular_score도 초기화 후 병합\n",
    "    hybrid_recs_df = pd.merge(hybrid_recs_df, popular_movies_df_pandas[['movieId', 'popular_score']], on='movieId', how='left', suffixes=('_old', ''))\n",
    "    hybrid_recs_df['popular_score'] = hybrid_recs_df['popular_score'].fillna(0) # merge 시 NaN 처리\n",
    "\n",
    "    # 최종 가중치 점수 계산\n",
    "    hybrid_recs_df['final_score'] = (hybrid_recs_df['content_score'] * content_weight) + \\\n",
    "                                    (hybrid_recs_df['popular_score'] * popular_weight)\n",
    "\n",
    "    # 사용자가 이미 본 영화는 추천에서 제외\n",
    "    hybrid_recs_df = hybrid_recs_df[~hybrid_recs_df['movieId'].isin(seen_movie_ids)]\n",
    "\n",
    "    # 최종 점수를 기준으로 정렬하고 상위 N개 추천\n",
    "    final_recommendations_pandas = hybrid_recs_df.sort_values(by='final_score', ascending=False) \\\n",
    "                                                 .drop_duplicates(subset=['movieId']) \\\n",
    "                                                 .head(num_recommendations_total) \\\n",
    "                                                 .reset_index(drop=True)\n",
    "\n",
    "    # Spark DataFrame으로 변환\n",
    "    schema = StructType([StructField(\"movieId\", IntegerType(), True),\n",
    "                         StructField(\"content_score\", DoubleType(), True),\n",
    "                         StructField(\"popular_score\", DoubleType(), True),\n",
    "                         StructField(\"final_score\", DoubleType(), True)]) # 점수 컬럼도 포함하여 반환 가능\n",
    "    # 다만 평가 함수는 movieId만 필요하므로, 여기서는 movieId만 포함된 DF로 반환\n",
    "    final_recommendations_spark = spark.createDataFrame(final_recommendations_pandas[['movieId']], StructType([StructField(\"movieId\", IntegerType(), True)]))\n",
    "\n",
    "    return final_recommendations_spark\n",
    "\n",
    "# 5. 모델 테스트 (사용자 입력) - 주석 처리\n",
    "# 예제 사용:\n",
    "# num_recommendations_output = 10\n",
    "# content_w = 0.7\n",
    "# popular_w = 0.3\n",
    "\n",
    "# # 테스트할 입력 영화 ID (예: Toy Story, Jumanji, Grumpier Old Men)\n",
    "# # movies_df.head()를 보고 실제 존재하는 영화 ID를 입력하세요.\n",
    "# example_user_movie_ids = [1, 2, 3] # 예시 ID\n",
    "\n",
    "# print(f\"\\n입력된 영화: {[get_title_from_id(mid) for mid in example_user_movie_ids]} (ID: {example_user_movie_ids})를 기반으로 영화를 추천합니다:\")\n",
    "# recommended_df = recommend_movies_weighted_hybrid(example_user_movie_ids, num_recommendations_output,\n",
    "#                                                   content_weight=content_w, popular_weight=popular_w)\n",
    "\n",
    "# # recommended_df는 movieId만 포함하므로, display 함수로 보여주기 위해 다시 join 필요\n",
    "# final_display_df = recommended_df.join(movies_df_spark, \"movieId\", \"left\").select('title', 'genres')\n",
    "# print(\"\\n--- 추천 결과 ---\")\n",
    "# display(final_display_df)\n",
    "\n",
    "\n",
    "# 6. 모델 성능 평가 및 시각화\n",
    "\n",
    "# NDCG (Normalized Discounted Cumulative Gain) 계산 함수\n",
    "def calculate_ndcg_at_k(recommended_items, relevant_items, k):\n",
    "    \"\"\"\n",
    "    NDCG@k를 계산합니다.\n",
    "    Args:\n",
    "        recommended_items (list): 추천된 아이템 ID 리스트.\n",
    "        relevant_items (set): 관련성 있는 아이템 ID 집합.\n",
    "        k (int): 평가할 상위 K개 아이템.\n",
    "    Returns:\n",
    "        float: NDCG@k 값.\n",
    "    \"\"\"\n",
    "    if not relevant_items:\n",
    "        return 0.0\n",
    "\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "\n",
    "    for i in range(k):\n",
    "        if i < len(recommended_items):\n",
    "            item = recommended_items[i]\n",
    "            if item in relevant_items:\n",
    "                dcg += 1.0 / np.log2(i + 2) # i+1은 0-based index이므로, log2(position + 1)\n",
    "        \n",
    "        # Ideal DCG (가장 이상적인 추천 순서)\n",
    "        if i < len(relevant_items):\n",
    "            idcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# 평가 지표 계산 함수 (Precision@k, Recall@k, NDCG@k)\n",
    "def evaluate_recommender(model_func, movies_df_eval, ratings_df_eval, indices_eval, cosine_sim_matrix_eval,\n",
    "                         test_ratings_df_eval, train_ratings_df_eval, k=10, content_w=0.7, popular_w=0.3):\n",
    "    \"\"\"\n",
    "    추천 시스템의 평균 Precision@k, Recall@k, NDCG@k를 계산하고,\n",
    "    각 유저별 추천 결과를 포함하는 DataFrame을 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        model_func (function): 영화 추천을 수행하는 함수 (여기서는 recommend_movies_weighted_hybrid).\n",
    "        movies_df_eval (pd.DataFrame): 영화 정보 DataFrame.\n",
    "        ratings_df_eval (pd.DataFrame): 전체 평점 정보 DataFrame (훈련 데이터를 포함).\n",
    "        indices_eval (pd.Series): 영화 제목과 인덱스 매핑 Series.\n",
    "        cosine_sim_matrix_eval (np.array): 코사인 유사도 행렬.\n",
    "        test_ratings_df_eval (pd.DataFrame): 테스트용 평점 DataFrame.\n",
    "        train_ratings_df_eval (pd.DataFrame): 훈련용 평점 DataFrame.\n",
    "        k (int): 평가할 상위 K개 영화.\n",
    "        content_w (float): 콘텐츠 기반 추천 가중치.\n",
    "        popular_w (float): 인기/고평점 추천 가중치.\n",
    "    Returns:\n",
    "        tuple: (평균 Precision@k, 평균 Recall@k, 평균 NDCG@k, 평가된 사용자 수, 사용자별 추천 결과 DataFrame)\n",
    "    \"\"\"\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_ndcg = 0\n",
    "    num_users_evaluated = 0\n",
    "    \n",
    "    # 사용자별 추천 결과를 저장할 리스트\n",
    "    user_recommendations_data = []\n",
    "\n",
    "    # 테스트 데이터셋에서 임의의 사용자 샘플링 (최대 100명 또는 고유 사용자 수 중 더 작은 값)\n",
    "    sample_users = test_ratings_df_eval['userId'].sample(min(100, test_ratings_df_eval['userId'].nunique()), random_state=42).unique()\n",
    "\n",
    "    for user_id in sample_users:\n",
    "        # 해당 사용자의 훈련 데이터에서 가장 높은 평점을 준 영화들을 '입력 영화'로 가정\n",
    "        # (4점 이상 평점을 준 영화들 중 상위 3개)\n",
    "        user_train_movies_high_rated = train_ratings_df_eval[(train_ratings_df_eval['userId'] == user_id) & (train_ratings_df_eval['rating'] >= 4)] \\\n",
    "                                            .sort_values(by='rating', ascending=False)\n",
    "        \n",
    "        if len(user_train_movies_high_rated) < 3: # 최소 3개 이상의 높은 평점 영화가 없으면 평가 제외\n",
    "            continue\n",
    "            \n",
    "        seed_movie_ids = user_train_movies_high_rated.head(3)['movieId'].tolist()\n",
    "\n",
    "        if not seed_movie_ids:\n",
    "            continue\n",
    "\n",
    "        # 추천 받기\n",
    "        recommended_movies_df_spark = model_func(\n",
    "            seed_movie_ids, k, content_weight=content_w, popular_weight=popular_w\n",
    "        )\n",
    "        recommended_movie_ids_list = [row.movieId for row in recommended_movies_df_spark.collect()]\n",
    "        \n",
    "        if not recommended_movie_ids_list:\n",
    "            continue\n",
    "\n",
    "        # 실제 관련성 있는 영화: 테스트 데이터에서 해당 사용자가 4점 이상 평점을 준 영화\n",
    "        actual_relevant_movies_df = test_ratings_df_eval[(test_ratings_df_eval['userId'] == user_id) & (test_ratings_df_eval['rating'] >= 4)]\n",
    "        actual_relevant_movie_ids = set(actual_relevant_movies_df['movieId'].tolist())\n",
    "\n",
    "        # 추천된 영화 ID 리스트를 k개로 자르기\n",
    "        recommended_k = recommended_movie_ids_list[:k]\n",
    "\n",
    "        # Precision@k\n",
    "        true_positives = len(set(recommended_k).intersection(actual_relevant_movie_ids))\n",
    "        precision_k = true_positives / k if k > 0 else 0\n",
    "\n",
    "        # Recall@k\n",
    "        recall_k = true_positives / len(actual_relevant_movie_ids) if len(actual_relevant_movie_ids) > 0 else 0\n",
    "\n",
    "        # NDCG@k\n",
    "        ndcg_k = calculate_ndcg_at_k(recommended_k, actual_relevant_movie_ids, k)\n",
    "\n",
    "        total_precision += precision_k\n",
    "        total_recall += recall_k\n",
    "        total_ndcg += ndcg_k\n",
    "        num_users_evaluated += 1\n",
    "\n",
    "        # 사용자별 추천 결과 저장\n",
    "        user_recommendations_data.append({\n",
    "            'userId': user_id,\n",
    "            'seed_movie_ids': seed_movie_ids,\n",
    "            'recommended_movie_ids': recommended_k,\n",
    "            'actual_relevant_movie_ids': list(actual_relevant_movie_ids), # Set to list for DataFrame\n",
    "            'precision_at_k': precision_k,\n",
    "            'recall_at_k': recall_k,\n",
    "            'ndcg_at_k': ndcg_k\n",
    "        })\n",
    "\n",
    "    user_recs_df = pd.DataFrame(user_recommendations_data)\n",
    "\n",
    "\n",
    "    if num_users_evaluated == 0:\n",
    "        return 0, 0, 0, 0, pd.DataFrame()\n",
    "\n",
    "    avg_precision = total_precision / num_users_evaluated\n",
    "    avg_recall = total_recall / num_users_evaluated\n",
    "    avg_ndcg = total_ndcg / num_users_evaluated\n",
    "\n",
    "    return avg_precision, avg_recall, avg_ndcg, num_users_evaluated, user_recs_df\n",
    "\n",
    "# 모델 성능 평가 함수 호출\n",
    "def model_performance_evaluation(k_val=10, content_weight=0.7, popular_weight=0.3):\n",
    "    print(\"\\n모델 성능 평가를 시작합니다...\")\n",
    "    # evaluate_recommender 함수에 train_ratings_df_eval를 전달 (훈련 데이터)\n",
    "    avg_precision, avg_recall, avg_ndcg, num_evaluated_users, user_recs_df = evaluate_recommender(\n",
    "        recommend_movies_weighted_hybrid, movies_df, ratings_df, indices, cosine_sim, \n",
    "        test_ratings_df, ratings_df, # ratings_df는 train_df_spark.toPandas()로 생성되었으므로, 훈련 데이터 역할을 합니다.\n",
    "        k=k_val, # 평가할 K 값\n",
    "        content_w=content_weight, popular_w=popular_weight # 가중치 파라미터 전달\n",
    "    )\n",
    "\n",
    "    print(f\"\\n평가된 사용자 수: {num_evaluated_users}\")\n",
    "    print(f\"평균 Precision@{k_val}: {avg_precision:.4f}\")\n",
    "    print(f\"평균 Recall@{k_val}: {avg_recall:.4f}\")\n",
    "    print(f\"평균 NDCG@{k_val}: {avg_ndcg:.4f}\")\n",
    "\n",
    "    # 성능 시각화\n",
    "    metrics = [f'Precision@{k_val}', f'Recall@{k_val}', f'NDCG@{k_val}']\n",
    "    values = [avg_precision, avg_recall, avg_ndcg]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=metrics, y=values, palette='viridis')\n",
    "    plt.title(f'Recommendation System Performance Metrics (k={k_val}, Content Weight={content_weight}, Popular Weight={popular_weight})')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', va='bottom', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "    # 사용자별 추천 결과 DataFrame 출력\n",
    "    print(\"\\n--- 사용자별 추천 결과 (샘플) ---\")\n",
    "    # recommended_movie_ids를 영화 제목으로 변환하여 보기 좋게 출력\n",
    "    user_recs_df['recommended_movie_titles'] = user_recs_df['recommended_movie_ids'].apply(\n",
    "        lambda ids: [get_title_from_id(mid) for mid in ids]\n",
    "    )\n",
    "    user_recs_df['seed_movie_titles'] = user_recs_df['seed_movie_ids'].apply(\n",
    "        lambda ids: [get_title_from_id(mid) for mid in ids]\n",
    "    )\n",
    "    user_recs_df['actual_relevant_movie_titles'] = user_recs_df['actual_relevant_movie_ids'].apply(\n",
    "        lambda ids: [get_title_from_id(mid) for mid in ids]\n",
    "    )\n",
    "\n",
    "    # 필요한 컬럼만 선택하여 출력\n",
    "    display(user_recs_df[['userId', 'seed_movie_titles', 'recommended_movie_titles', 'precision_at_k', 'recall_at_k', 'ndcg_at_k']])\n",
    "\n",
    "# 평가 실행 (예: k=10, 콘텐츠 가중치 0.7, 인기 가중치 0.3)\n",
    "# 이 가중치 값들을 변경하면서 최적의 성능을 찾아보세요.\n",
    "model_performance_evaluation(k_val=10, content_weight=0.5, popular_weight=0.5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Content-Based (Hybrid) test 예제 코드",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
